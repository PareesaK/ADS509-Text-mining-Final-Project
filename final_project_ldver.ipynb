{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "222359ad-938e-4562-b344-74a880b1e77e",
   "metadata": {},
   "source": [
    "# ADS 509 Text Mining Project\n",
    "\n",
    "**Lorena Dorado & Parisa Kamizi** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e633187-7547-4b65-9f38-678770f04ca1",
   "metadata": {},
   "source": [
    "## Load and Explore the Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90ef2292-8fdc-474f-9c62-358d9eab224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import html\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from langdetect import DetectorFactory\n",
    "from typing import List, Dict, Any\n",
    "import random\n",
    "\n",
    "# Text processing\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from langdetect import detect\n",
    "import spacy\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Topic Modeling\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, TruncatedSVD, LatentDirichletAllocation\n",
    "import pyLDAvis\n",
    "import pyLDAvis.lda_model\n",
    "import pyLDAvis.gensim_models\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Download required NLTK resources\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c267811-b3e8-4b4a-99c0-13b0b80de743",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-22 16:17:22,134 - INFO - Setup complete\n"
     ]
    }
   ],
   "source": [
    "# Configure Logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('text_mining.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(\"Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc6195ad-9e5f-4ab2-b72d-92544e785417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up text processing configurations\n",
    "# stop_words = set(stopwords.words('english')) ADD other languages\n",
    "stop_words = set(stopwords.words('english') + \n",
    "                 stopwords.words('spanish') + \n",
    "                 stopwords.words('french') + \n",
    "                 stopwords.words('german'))\n",
    "\n",
    "# Add custom stopwords\n",
    "custom_stopwords = {'ul', 'li', 'ol', 'div', 'span', 'href', 'src', 'img', 'p', 'br', 'nbsp', 'char', 'id', 'av', 'lv'}\n",
    "stop_words.update(custom_stopwords)\n",
    "\n",
    "website_stopwords = ['transparency', 'accept', 'partner', 'click', 'consent', 'cookie', 'policy', 'privacy', 'terms', 'use', 'agreement', 'site']\n",
    "stop_words.update(website_stopwords)\n",
    "\n",
    "punctuation_set = set(string.punctuation) - {\"#\"}  # Keep hashtags\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3b9603-9b4d-487e-8753-19d387fb763d",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3876a3a7-c344-4e66-9dc9-f6e4ccb37c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-22 16:17:22,185 - INFO - Successfully loaded .\\deepseek_20250214.csv\n",
      "2025-02-22 16:17:22,185 - INFO - Successfully loaded .\\deepseek_20250220.csv\n",
      "2025-02-22 16:17:22,185 - INFO - Successfully loaded .\\deepseek_20250222.csv\n",
      "2025-02-22 16:17:22,200 - INFO - Successfully loaded .\\Deepseek_Day_Five.csv\n",
      "2025-02-22 16:17:22,200 - INFO - Successfully loaded .\\Deepseek_Day_Four.csv\n",
      "2025-02-22 16:17:22,212 - INFO - Successfully loaded .\\Deepseek_Day_One.csv\n",
      "2025-02-22 16:17:22,212 - INFO - Successfully loaded .\\Deepseek_Day_Three.csv\n",
      "2025-02-22 16:17:22,212 - INFO - Successfully loaded .\\Deepseek_Day_Two.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1041 entries, 0 to 1040\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype              \n",
      "---  ------       --------------  -----              \n",
      " 0   source       856 non-null    object             \n",
      " 1   date         856 non-null    datetime64[ns, UTC]\n",
      " 2   text         856 non-null    object             \n",
      " 3   title        856 non-null    object             \n",
      " 4   description  828 non-null    object             \n",
      "dtypes: datetime64[ns, UTC](1), object(4)\n",
      "memory usage: 40.8+ KB\n",
      "None\n",
      "\n",
      "First few rows:\n",
      "             source                      date  \\\n",
      "0   Android Central 2025-02-10 18:49:23+00:00   \n",
      "1         MacRumors 2025-02-11 14:54:38+00:00   \n",
      "2  Business Insider 2025-02-07 14:04:28+00:00   \n",
      "3  Business Insider 2025-02-10 07:41:09+00:00   \n",
      "4  Business Insider 2025-02-12 13:06:10+00:00   \n",
      "\n",
      "                                                text  \\\n",
      "0  What you need to know\\r\\n<ul><li>Honor is upgr...   \n",
      "1  Apple in recent months \"passed over\" the Chine...   \n",
      "2  Aiden Gomez is one of the Google Brain researc...   \n",
      "3  Demis Hassabis, cofounder and CEO of Google De...   \n",
      "4  BYD has become the latest automaker to incorpo...   \n",
      "\n",
      "                                               title  \\\n",
      "0  Honor teams up with Gemini and ChatGPT’s bigge...   \n",
      "1  Apple Reportedly 'Passed Over' DeepSeek as App...   \n",
      "2  Aidan Gomez helped spark the generative AI boo...   \n",
      "3  Google's AI lab CEO said DeepSeek is China's '...   \n",
      "4  DeepSeek's AI is the hot new feature for Chine...   \n",
      "\n",
      "                                         description  \n",
      "0  Honor is boosting its AI assistant by teaming ...  \n",
      "1  Apple in recent months \"passed over\" the Chine...  \n",
      "2  The Cohere CEO and former Google Brain member ...  \n",
      "3  \"It's using known techniques, actually many of...  \n",
      "4  Tesla rivals BYD, Geely, and Great Wall have a...  \n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "column_mapping = {\n",
    "    'source_name': 'source',\n",
    "    'publishedAt': 'date',\n",
    "    'content': 'text',\n",
    "    'title': 'title',\n",
    "    'description': 'description'\n",
    "}\n",
    "\n",
    "csv_files = glob.glob(os.path.join('.', '*.csv'))\n",
    "dfs = []\n",
    "\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        temp_df = pd.read_csv(file)\n",
    "        dfs.append(temp_df)\n",
    "        logger.info(f\"Successfully loaded {file}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error reading file {file}: {str(e)}\")\n",
    "\n",
    "if not dfs:\n",
    "    raise ValueError(\"No CSV files were successfully loaded\")\n",
    "\n",
    "news_df = pd.concat(dfs, ignore_index=True)\n",
    "news_df = news_df[column_mapping.keys()].rename(columns=column_mapping)\n",
    "news_df['date'] = pd.to_datetime(news_df['date'])\n",
    "\n",
    "print(\"\\nInitial Dataset Info:\")\n",
    "print(news_df.info())\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(news_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b28dfdc-358b-484e-8e96-ce90554fb9f4",
   "metadata": {},
   "source": [
    "## Data Cleaning with Tokenization and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5cf8811-890e-4733-b356-1e0f2f9c2e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Text processing pipeline functions\n",
    "def validate_text(text):\n",
    "    \"\"\"Check if text is valid\"\"\"\n",
    "    return \"\" if not isinstance(text, str) or pd.isna(text) else text\n",
    "\n",
    "def basic_clean(text):\n",
    "    \"\"\"Basic text cleaning\"\"\"\n",
    "    return (html.unescape(text)\n",
    "            .lower()\n",
    "            .replace('\\n', ' ')\n",
    "            .replace('\\r', ' '))\n",
    "\n",
    "def remove_special_chars(text):\n",
    "    \"\"\"Remove special characters and patterns\"\"\"\n",
    "    return re.sub(r'\\[\\+\\d+ chars\\]|https?://\\S+|â€™|â€\"|[^\\w\\s\\-\\'.,!?]', ' ', text)\n",
    "\n",
    "def remove_num_patterns(text):\n",
    "    \"\"\"Remove date patterns and numbers (including those with commas)\"\"\"\n",
    "    return re.sub(r'\\b\\d{1,4}[-/]\\d{1,2}[-/]\\d{1,4}\\b|\\b\\d{1,3}(,\\d{3})*(\\.\\d+)?\\b|\\b\\d+\\b', '', text)\n",
    "\n",
    "def clean_whitespace(text):\n",
    "    \"\"\"Clean extra whitespace\"\"\"\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "def remove_punct(text):\n",
    "    \"\"\"Remove punctuation\"\"\"\n",
    "    return \"\".join(ch for ch in text if ch not in punctuation_set)\n",
    "\n",
    "def get_tokens(text):\n",
    "    \"\"\"Get tokens without stopwords, lemmatize, remove numbers, and filter short tokens\"\"\"\n",
    "    doc = nlp(text)\n",
    "    return [token.lemma_.lower() for token in doc \n",
    "            if token.is_alpha \n",
    "            and len(token.text) > 2 \n",
    "            and not token.is_stop \n",
    "            and token.lemma_.lower() not in stop_words \n",
    "            and not token.like_num]\n",
    "\n",
    "def detect_lang(text):\n",
    "    \"\"\"Detect language safely\"\"\"\n",
    "    try:\n",
    "        return 'unknown' if len(text.strip()) < 50 else detect(text)\n",
    "    except:\n",
    "        return 'unknown'\n",
    "\n",
    "def remove_duplicates(df):\n",
    "    \"\"\"Remove duplicate articles based on content similarity\"\"\"\n",
    "    df['text_signature'] = df['title'] + df['text'].str[:200]\n",
    "    original_len = len(df)\n",
    "    df = df.drop_duplicates(subset=['text_signature'])\n",
    "    df = df.drop('text_signature', axis=1)\n",
    "    logger.info(f\"Removed {original_len - len(df)} duplicate articles\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c831ffce-1614-4801-a677-c5308505f368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text, steps=None):\n",
    "    if steps is None:\n",
    "        steps = ['validate', 'basic', 'special', 'num_patterns', 'whitespace', 'punct', 'tokens']\n",
    "    \n",
    "    text = validate_text(text)\n",
    "    \n",
    "    pipeline_steps = {\n",
    "        'validate': validate_text,\n",
    "        'basic': basic_clean,\n",
    "        'special': remove_special_chars,\n",
    "        'num_patterns': remove_num_patterns,\n",
    "        'whitespace': clean_whitespace,\n",
    "        'punct': remove_punct,\n",
    "        'tokens': get_tokens\n",
    "    }\n",
    "    \n",
    "    for step in steps:\n",
    "        text = pipeline_steps[step](text)\n",
    "    \n",
    "    return text if isinstance(text, list) else text  # Return tokens as a list if the last step was tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0f2a4ff-c859-4361-ab3d-2d30322a9f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-22 16:17:22,285 - INFO - Removing duplicates...\n",
      "2025-02-22 16:17:22,285 - INFO - Removed 362 duplicate articles\n",
      "2025-02-22 16:17:22,285 - INFO - Removing rows with NaN in 'text' column...\n",
      "2025-02-22 16:17:22,285 - INFO - Removed 1 rows with NaN values in 'text' column.\n",
      "2025-02-22 16:17:22,300 - INFO - Processing text...\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 678/678 [00:00<00:00, 43391.34it/s]\n",
      "2025-02-22 16:17:22,336 - INFO - Detecting languages...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 678/678 [00:04<00:00, 151.19it/s]\n",
      "2025-02-22 16:17:26,821 - INFO - Creating cleaned content...\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 678/678 [00:00<00:00, 21745.61it/s]\n",
      "2025-02-22 16:17:26,852 - INFO - Generating tokens...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 678/678 [00:05<00:00, 117.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed DataFrame columns:\n",
      "['source', 'date', 'text', 'title', 'description', 'clean_text', 'language', 'cleaned_content', 'Cleaned_Text', 'Tokens']\n",
      "\n",
      "Sample of processed data:\n",
      "             source                      date  \\\n",
      "0   Android Central 2025-02-10 18:49:23+00:00   \n",
      "1         MacRumors 2025-02-11 14:54:38+00:00   \n",
      "2  Business Insider 2025-02-07 14:04:28+00:00   \n",
      "3  Business Insider 2025-02-10 07:41:09+00:00   \n",
      "4  Business Insider 2025-02-12 13:06:10+00:00   \n",
      "\n",
      "                                          clean_text language  \\\n",
      "0  what you need to know ul li honor is upgrading...       en   \n",
      "1  apple in recent months passed over the chinese...       en   \n",
      "2  aiden gomez is one of the google brain researc...       en   \n",
      "3  demis hassabis, cofounder and ceo of google de...       en   \n",
      "4  byd has become the latest automaker to incorpo...       en   \n",
      "\n",
      "                                              Tokens  \n",
      "0  [need, know, ullihonor, upgrade, yoyo, assista...  \n",
      "1  [apple, recent, month, pass, chinese, artifici...  \n",
      "2  [aiden, gomez, google, brain, researcher, coau...  \n",
      "3  [demis, hassabis, cofounder, ceo, google, deep...  \n",
      "4  [byd, late, automaker, incorporate, deepseek, ...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "logger.info(\"Removing duplicates...\")\n",
    "news_df = remove_duplicates(news_df)\n",
    "\n",
    "# Remove rows with NaN in 'text' column\n",
    "logger.info(\"Removing rows with NaN in 'text' column...\")\n",
    "initial_row_count = len(news_df)\n",
    "news_df = news_df.dropna(subset=['text'])\n",
    "removed_row_count = initial_row_count - len(news_df)\n",
    "logger.info(f\"Removed {removed_row_count} rows with NaN values in 'text' column.\")\n",
    "\n",
    "# Process text\n",
    "logger.info(\"Processing text...\")\n",
    "tqdm.pandas()\n",
    "news_df['clean_text'] = news_df['text'].progress_apply(\n",
    "    lambda x: process_text(x, ['validate', 'basic', 'special', 'num_patterns', 'whitespace']))\n",
    "\n",
    "# Detect languages\n",
    "logger.info(\"Detecting languages...\")\n",
    "news_df['language'] = news_df['clean_text'].progress_apply(detect_lang)\n",
    "\n",
    "# Create cleaned content\n",
    "logger.info(\"Creating cleaned content...\")\n",
    "news_df['cleaned_content'] = news_df['text'].progress_apply(\n",
    "    lambda x: process_text(x, ['validate', 'basic', 'punct', 'whitespace']))\n",
    "\n",
    "# Generate tokens\n",
    "logger.info(\"Generating tokens...\")\n",
    "def get_cleaned_text_and_tokens(text):\n",
    "    cleaned = process_text(text, ['validate', 'basic', 'punct', 'whitespace'])\n",
    "    tokens = get_tokens(cleaned)\n",
    "    return ' '.join(tokens), tokens\n",
    "\n",
    "temp_results = news_df['text'].progress_apply(get_cleaned_text_and_tokens)\n",
    "news_df['Cleaned_Text'] = temp_results.apply(lambda x: x[0])\n",
    "news_df['Tokens'] = temp_results.apply(lambda x: x[1])\n",
    "\n",
    "# Display processed data sample\n",
    "print(\"\\nProcessed DataFrame columns:\")\n",
    "print(news_df.columns.tolist())\n",
    "print(\"\\nSample of processed data:\")\n",
    "print(news_df[['source', 'date', 'clean_text', 'language', 'Tokens']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea86121-29d9-400a-8125-db390416df01",
   "metadata": {},
   "source": [
    "## Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1070262e-5c02-482c-b99c-fea3b6e5dcd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Descriptive Statistics for 'News Articles':\n",
      "--------------------------------------------------\n",
      "Total documents: 678\n",
      "\n",
      "Token-level Statistics:\n",
      "Total tokens: 10,904\n",
      "Unique tokens: 4,327\n",
      "Total characters: 72,706\n",
      "Lexical diversity: 0.397\n",
      "\n",
      "Top 10 most frequent tokens:\n",
      "deepseek: 502\n",
      "openai: 149\n",
      "model: 121\n",
      "chinese: 110\n",
      "artificial: 81\n",
      "chatgpt: 76\n",
      "nvidia: 67\n",
      "tech: 66\n",
      "new: 64\n",
      "app: 62\n"
     ]
    }
   ],
   "source": [
    "def descriptive_stats_all(df: pd.DataFrame, tokens_col: str = 'Tokens', \n",
    "                         text_col: str = 'text', title: str = \"Dataset\",\n",
    "                         num_tokens: int = 5, plot: bool = True) -> Dict[str, Any]:\n",
    "\n",
    "    # Initialize results dictionary\n",
    "    stats = {}\n",
    "    \n",
    "    # Get all tokens\n",
    "    all_tokens = [token for tokens in df[tokens_col] for token in tokens]\n",
    "    token_counts = Counter(all_tokens)\n",
    "    \n",
    "    # Basic token statistics\n",
    "    stats['total_tokens'] = len(all_tokens)\n",
    "    stats['unique_tokens'] = len(set(all_tokens))\n",
    "    stats['total_characters'] = len(''.join(all_tokens))\n",
    "    stats['lexical_diversity'] = stats['unique_tokens'] / stats['total_tokens'] if stats['total_tokens'] > 0 else 0\n",
    "    \n",
    "    # Document statistics\n",
    "    stats['total_documents'] = len(df)\n",
    "    \n",
    "    # Token length statistics\n",
    "    token_lengths = [len(token) for token in all_tokens]\n",
    "\n",
    "    # Top tokens\n",
    "    stats['top_tokens'] = token_counts.most_common(num_tokens)\n",
    "    \n",
    "    # Print results if verbose\n",
    "    print(f\"\\nDescriptive Statistics for '{title}':\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Total documents: {stats['total_documents']:,}\")\n",
    "    \n",
    "    print(f\"\\nToken-level Statistics:\")\n",
    "    print(f\"Total tokens: {stats['total_tokens']:,}\")\n",
    "    print(f\"Unique tokens: {stats['unique_tokens']:,}\")\n",
    "    print(f\"Total characters: {stats['total_characters']:,}\")\n",
    "    print(f\"Lexical diversity: {stats['lexical_diversity']:.3f}\")\n",
    "    \n",
    "    print(f\"\\nTop {num_tokens} most frequent tokens:\")\n",
    "    for token, count in stats['top_tokens']:\n",
    "        print(f\"{token}: {count:,}\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "stats = descriptive_stats_all(news_df, tokens_col='Tokens', text_col='text',\n",
    "                              title=\"News Articles\", num_tokens=10, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed838cc1-ea42-4851-8714-9121aa5c79c0",
   "metadata": {},
   "source": [
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84eaa155-59fc-4c5b-923b-9872593b30e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values in 'clean_text': 0\n",
      "Shape of DataFrame after removing NaN values: (678, 12)\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values\n",
    "print(f\"Number of NaN values in 'clean_text': {news_df['clean_text'].isna().sum()}\")\n",
    "\n",
    "# Remove rows with NaN values\n",
    "news_df = news_df.dropna(subset=['clean_text'])\n",
    "print(f\"Shape of DataFrame after removing NaN values: {news_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fd8de81-577d-4be1-a7b7-17d97af2e3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=list(stop_words), max_features=5000, max_df=0.95, min_df=2)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(news_df['clean_text'])\n",
    "\n",
    "# Create Count vectorizer\n",
    "count_vectorizer = CountVectorizer(stop_words=list(stop_words), max_features=5000, max_df=0.95, min_df=2)\n",
    "count_matrix = count_vectorizer.fit_transform(news_df['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "556be751-af49-467f-9389-2dbf66c217ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display topics\n",
    "def display_topics(model, features, no_top_words=5):\n",
    "    for topic, words in enumerate(model.components_):\n",
    "        total = words.sum()\n",
    "        largest = words.argsort()[::-1] # invert sort order\n",
    "        print(\"\\nTopic %02d\" % topic)\n",
    "        for i in range(0, no_top_words):\n",
    "            print(\"  %s (%2.2f)\" % (features[largest[i]], abs(words[largest[i]]*100.0/total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a271b3a8-e155-42d3-89d6-d0ccdde8a312",
   "metadata": {},
   "source": [
    "## NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "015a4a5c-39d0-4db2-ada9-8a47ac537c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF Topics:\n",
      "\n",
      "Topic 00\n",
      "  iab (9.55)\n",
      "  words (9.55)\n",
      "  partners (9.55)\n",
      "  device (9.29)\n",
      "  framework (9.26)\n",
      "\n",
      "Topic 01\n",
      "  deepseek (20.24)\n",
      "  r1 (6.16)\n",
      "  chatgpt (2.73)\n",
      "  nvidia (1.99)\n",
      "  bloomberg (1.12)\n",
      "\n",
      "Topic 02\n",
      "  chinese (1.80)\n",
      "  model (1.37)\n",
      "  intelligence (1.14)\n",
      "  tech (1.09)\n",
      "  app (1.08)\n",
      "\n",
      "Topic 03\n",
      "  openai (9.51)\n",
      "  chatgpt (3.40)\n",
      "  o3 (3.16)\n",
      "  altman (3.15)\n",
      "  mini (3.11)\n",
      "\n",
      "Topic 04\n",
      "  weekly (5.24)\n",
      "  coverage (4.91)\n",
      "  learn (4.91)\n",
      "  updates (4.91)\n",
      "  newsletters (4.89)\n"
     ]
    }
   ],
   "source": [
    "# Fit NMF model\n",
    "n_topics = 5\n",
    "nmf_model = NMF(n_components=n_topics, random_state=42)\n",
    "nmf_output = nmf_model.fit_transform(tfidf_matrix)\n",
    "\n",
    "# Display the topics\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "print(\"NMF Topics:\")\n",
    "display_topics(nmf_model, tfidf_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5e293b-af35-49ed-9dda-dd00f0d6d348",
   "metadata": {},
   "source": [
    "## LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a316060-8177-4ae6-8877-ce4c56b0c931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSA Topics:\n",
      "\n",
      "Topic 00\n",
      "  iab (5.07)\n",
      "  partners (5.07)\n",
      "  words (5.07)\n",
      "  device (4.94)\n",
      "  part (4.92)\n",
      "\n",
      "Topic 01\n",
      "  deepseek (7.31)\n",
      "  r1 (2.44)\n",
      "  openai (2.14)\n",
      "  chatgpt (1.72)\n",
      "  model (1.01)\n",
      "\n",
      "Topic 02\n",
      "  deepseek (2.25)\n",
      "  r1 (0.86)\n",
      "  chatgpt (0.60)\n",
      "  flyer (0.25)\n",
      "  gpu (0.21)\n",
      "\n",
      "Topic 03\n",
      "  openai (38.20)\n",
      "  o3 (14.33)\n",
      "  mini (14.09)\n",
      "  altman (13.45)\n",
      "  chatgpt (13.25)\n",
      "\n",
      "Topic 04\n",
      "  weekly (18.56)\n",
      "  learn (17.60)\n",
      "  updates (17.60)\n",
      "  coverage (17.60)\n",
      "  newsletters (17.53)\n"
     ]
    }
   ],
   "source": [
    "# Fit LSA model\n",
    "lsa_model = TruncatedSVD(n_components=n_topics, random_state=42)\n",
    "lsa_output = lsa_model.fit_transform(tfidf_matrix)\n",
    "\n",
    "print(\"\\nLSA Topics:\")\n",
    "display_topics(lsa_model, tfidf_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c347b6-66e0-408a-97f7-0370e330c14f",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e830e45-0f4a-4823-b223-0de5362d0ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LDA Topics:\n",
      "\n",
      "Topic 00\n",
      "  deepseek (3.40)\n",
      "  chinese (2.53)\n",
      "  new (1.44)\n",
      "  model (1.41)\n",
      "  intelligence (1.26)\n",
      "\n",
      "Topic 01\n",
      "  artificial (1.98)\n",
      "  deepseek (1.81)\n",
      "  daily (1.63)\n",
      "  latest (1.43)\n",
      "  intelligence (1.29)\n",
      "\n",
      "Topic 02\n",
      "  deepseek (10.49)\n",
      "  nvidia (3.08)\n",
      "  r1 (2.34)\n",
      "  openai (1.13)\n",
      "  ia (1.09)\n",
      "\n",
      "Topic 03\n",
      "  deepseek (5.99)\n",
      "  model (1.70)\n",
      "  including (1.40)\n",
      "  r1 (1.39)\n",
      "  store (1.31)\n",
      "\n",
      "Topic 04\n",
      "  openai (6.77)\n",
      "  deepseek (4.28)\n",
      "  chatgpt (2.99)\n",
      "  mini (1.99)\n",
      "  o3 (1.93)\n"
     ]
    }
   ],
   "source": [
    "# Fit LDA model\n",
    "lda_model = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n",
    "lda_output = lda_model.fit_transform(count_matrix)\n",
    "\n",
    "print(\"\\nLDA Topics:\")\n",
    "display_topics(lda_model, count_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "154debfd-033f-49ce-9625-0a7856a4579c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el781216127847895363773558193\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el781216127847895363773558193_data = {\"mdsDat\": {\"x\": [-0.1037479246354286, 0.057320544583366814, -0.019455681903167894, 0.18282805196436175, -0.1169449900091321], \"y\": [0.034814060304124955, -0.14533479766174845, -0.0817094070581014, 0.10952684778908736, 0.0827032966266375], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [26.698550678674476, 23.27848677321275, 22.005745093125487, 18.21056445527639, 9.806652999710899]}, \"tinfo\": {\"Term\": [\"openai\", \"nvidia\", \"chatgpt\", \"mini\", \"o3\", \"deepseek\", \"altman\", \"sam\", \"artificial\", \"including\", \"model\", \"di\", \"daily\", \"chinese\", \"latest\", \"store\", \"device\", \"part\", \"intelligence\", \"partners\", \"iab\", \"words\", \"access\", \"framework\", \"r1\", \"news\", \"inteligencia\", \"o1\", \"exclusive\", \"information\", \"page\", \"platform\", \"researchers\", \"protection\", \"stories\", \"baidu\", \"everything\", \"news\", \"credit\", \"cisco\", \"san\", \"rivals\", \"jinping\", \"xi\", \"always\", \"techmeme\", \"wiz\", \"suspended\", \"success\", \"reporting\", \"country\", \"california\", \"early\", \"performance\", \"home\", \"february\", \"services\", \"giant\", \"owned\", \"column\", \"deepseeks\", \"south\", \"said\", \"korea\", \"data\", \"chinese\", \"new\", \"alibaba\", \"shows\", \"intelligence\", \"start\", \"available\", \"group\", \"free\", \"model\", \"getty\", \"images\", \"week\", \"top\", \"chatbot\", \"ki\", \"appeared\", \"via\", \"app\", \"deepseek\", \"artificial\", \"last\", \"china\", \"apple\", \"release\", \"latest\", \"tech\", \"photo\", \"company\", \"nvidia\", \"donald\", \"nvda\", \"flyer\", \"c\\u00f3digo\", \"v\\u00e0\", \"nhng\", \"si\", \"chino\", \"devices\", \"tsmc\", \"huang\", \"vn\", \"ch\\u00ednh\", \"abierto\", \"vamos\", \"house\", \"gpu\", \"table\", \"jensen\", \"fait\", \"ca\", \"terremoto\", \"trump\", \"contents\", \"tariffs\", \"d\\u00f3lares\", \"explicarte\", \"wiped\", \"ngi\", \"chips\", \"rise\", \"inteligencia\", \"figure\", \"modelo\", \"deepseek\", \"r1\", \"ia\", \"th\", \"wall\", \"semana\", \"google\", \"modelos\", \"tech\", \"us\", \"artificial\", \"high\", \"stocks\", \"openai\", \"ceo\", \"china\", \"market\", \"startup\", \"chatgpt\", \"world\", \"global\", \"apple\", \"chinese\", \"microsoft\", \"app\", \"week\", \"including\", \"iab\", \"partners\", \"words\", \"device\", \"part\", \"llms\", \"ollama\", \"llama\", \"framework\", \"pichai\", \"reinforcement\", \"know\", \"learning\", \"fraction\", \"store\", \"reasoning\", \"going\", \"parec\\u00eda\", \"justin\", \"sullivan\", \"im\\u00e1genes\", \"demostrado\", \"st\", \"jin\", \"downloaded\", \"launching\", \"europe\", \"directamente\", \"far\", \"na\", \"access\", \"meta\", \"information\", \"trained\", \"emergence\", \"language\", \"open\", \"large\", \"source\", \"momento\", \"model\", \"alphabet\", \"deepseek\", \"company\", \"models\", \"cost\", \"r1\", \"startup\", \"app\", \"chinese\", \"tech\", \"ia\", \"china\", \"images\", \"getty\", \"mini\", \"o3\", \"altman\", \"sam\", \"di\", \"artificiale\", \"intelligenza\", \"modello\", \"arxivlabs\", \"cinese\", \"work\", \"della\", \"tools\", \"plus\", \"reddit\", \"h\\u00e0nh\", \"flag\", \"suo\", \"directly\", \"sulla\", \"gold\", \"rush\", \"unsplash\", \"ama\", \"ask\", \"che\", \"api\", \"plusteam\", \"acce\", \"allows\", \"openai\", \"o1\", \"chatgpt\", \"pro\", \"deep\", \"deepseek\", \"gpt\", \"kong\", \"ceo\", \"could\", \"hong\", \"january\", \"models\", \"r1\", \"photo\", \"china\", \"new\", \"google\", \"one\", \"images\", \"getty\", \"world\", \"daily\", \"exclusive\", \"content\", \"newsletters\", \"amazon\", \"learn\", \"updates\", \"coverage\", \"spending\", \"deepseekdeepseek\", \"join\", \"amzn\", \"originally\", \"yoyo\", \"funciones\", \"paused\", \"advancements\", \"leading\", \"works\", \"joining\", \"construed\", \"educational\", \"informational\", \"purposes\", \"rating\", \"recommendation\", \"securities\", \"solicitation\", \"mas\", \"aten\\u00e7\\u00e3o\", \"newsletter\", \"computer\", \"authorities\", \"weekly\", \"com\", \"latest\", \"technology\", \"business\", \"temporarily\", \"mostly\", \"embargo\", \"thursday\", \"artificial\", \"industry\", \"intelligence\", \"apple\", \"startup\", \"sign\", \"deepseek\", \"inteligencia\", \"chinese\", \"big\", \"appeared\", \"korea\", \"story\", \"company\", \"south\", \"china\", \"week\"], \"Freq\": [143.0, 64.0, 72.0, 33.0, 32.0, 503.0, 28.0, 25.0, 70.0, 28.0, 71.0, 23.0, 14.0, 103.0, 29.0, 29.0, 24.0, 25.0, 51.0, 21.0, 21.0, 21.0, 30.0, 24.0, 99.0, 29.0, 23.0, 22.0, 11.0, 31.0, 10.79082409229533, 7.25202236088031, 7.250491755501418, 10.297234837696438, 5.482889667565356, 5.482251186407871, 5.481418215913578, 26.201464598770063, 4.598690485328757, 4.597920532855959, 4.597039552137762, 4.595056691976055, 3.7148681824794574, 3.7148681824794574, 3.714866276093166, 3.714866276093166, 3.714864525556102, 3.7145795631528036, 3.714464989314242, 3.7141831788967483, 8.119224579720676, 3.7115407867561614, 3.7106676877308824, 3.7101916290952275, 7.257087374918731, 7.254472290409392, 7.242353835948749, 12.243473932442791, 3.5703224318945366, 2.8303728259331256, 6.362600883407036, 18.573293680194308, 17.21001756291255, 13.289041197651061, 22.338558860688323, 60.63114096510578, 34.38964803269701, 8.381364470848718, 7.243831534776247, 30.068409441204523, 9.280357864945014, 10.237019591035104, 5.485582478486539, 7.58064300000009, 33.82757013249585, 21.363149537214518, 20.27802671310771, 19.763672829107513, 10.971094421603292, 16.348230954715685, 10.031441034032165, 9.083047163781451, 11.53488583632029, 19.72304712995791, 81.2533039091184, 24.50146250158569, 12.00694887744633, 18.894111436488267, 13.410536485793223, 9.682456382182925, 12.323554986682147, 14.537397189362437, 9.904566561841678, 10.180735560869397, 64.28531413011481, 11.244838627246294, 7.931740959400673, 7.10406706948781, 7.102972077495657, 6.237799996486191, 6.2371879701631965, 6.2360758716631395, 6.235375169647918, 6.234910372620292, 6.233693313366137, 5.371974945617257, 5.371017097422889, 5.371013493512538, 5.37015914170986, 5.3676629427167155, 5.321591497762558, 12.059794862631101, 4.505526487107528, 4.5055249094886145, 4.504919238004662, 4.504897063583528, 4.504445948094134, 16.50211537843223, 3.6390776602691375, 3.639077076107763, 3.639070228159869, 3.6387757950662465, 3.638616341791365, 3.638272670968765, 8.558772410601271, 7.074483120171722, 18.184445272263314, 6.79784349763286, 15.682700119411427, 218.754617254687, 48.7758786352323, 22.745696244091206, 9.385179463187498, 7.106969955272538, 6.682182139505361, 12.91693870318386, 9.575295683813255, 20.27466392486159, 13.939475835007284, 21.033190106064026, 8.663136313847426, 10.690562984161465, 23.630150491178483, 11.248378253610168, 14.71940779324818, 9.639969805532479, 12.688563689709342, 14.301127557523653, 9.11057312668632, 8.634627478212417, 9.179327267581842, 11.67680372507724, 7.92951439790489, 8.733841806785216, 8.446374167863347, 27.543167045533952, 20.701251996543416, 20.701251996543416, 20.701251996543416, 23.204680144979, 23.878869791315246, 7.010504406112286, 5.303614251091669, 5.267787995008275, 21.56156651157376, 4.4481981932315025, 4.446986993726692, 4.443056775029582, 4.441090457915859, 4.427497258722757, 25.841861116514735, 9.518241054939557, 3.592773108164484, 3.5866129479714077, 2.737350230852146, 2.737350230852146, 2.7373458220927587, 2.7373451038451093, 2.7368260509099565, 2.7360780926228294, 2.7360298185983662, 2.735920304812394, 2.735434452398411, 2.7348071267845246, 2.7345040286835527, 6.755329406747438, 23.274975773140504, 20.25057358682684, 23.045016784385798, 5.304108014175012, 5.789782455545768, 12.35808144300877, 22.80119170627369, 10.637887434514077, 15.168656546399264, 4.451195249022593, 33.57679322088516, 7.87244675440254, 118.15107448102553, 16.763148586001076, 16.098831165946446, 9.528156974642405, 27.41643843924707, 16.203473989674503, 15.873207180466634, 23.65958433897205, 17.063029971558418, 12.937142768573342, 11.806818655458983, 10.359554858559134, 10.006754385838533, 32.39521801244804, 31.54792059240339, 28.154201495670275, 24.761225439769103, 23.067820086744174, 7.801192738314599, 6.952866017422261, 6.105981776812635, 5.258321171811325, 5.257786431547957, 5.257767816614577, 5.257012332840772, 5.255795726491942, 5.250425073443631, 4.408875909474236, 4.393996681005306, 3.5620867967499183, 3.562084280976838, 3.560780301174168, 3.560798388242359, 3.5598668570640304, 3.5598668570640304, 3.5581931192753884, 3.557505660375615, 3.557504072196214, 6.9574890684665105, 10.317748513103995, 2.7139711361949583, 2.7139691587523203, 2.7139691587523203, 110.53720313925001, 17.4139241532024, 48.86150870214433, 9.481619133221457, 7.613084176747045, 69.83031222852401, 5.402194198894053, 5.279898574668958, 11.070724502573023, 5.966377330669981, 5.283287008161641, 7.100084238515673, 9.92006962423777, 14.19554023656631, 6.9584630731163815, 10.489421667732278, 8.046248045098919, 6.276776397613507, 5.86712171073979, 6.071730021654052, 5.917998792076725, 5.5402772773743525, 14.29903716241753, 10.3702138973033, 9.584022839738138, 8.800398075743578, 8.799705104709146, 8.014867780696848, 8.014867780696848, 8.01486778069685, 4.080497568314258, 4.080401984387453, 8.81889910423039, 3.299656100688817, 3.298642939303282, 2.5125890686361236, 2.5101524997114675, 2.508561033835181, 2.506842117343087, 8.494671555629287, 1.7287746526724936, 1.7287743982467962, 1.7287740538497571, 1.7287740538497571, 1.7287740538497571, 1.7287740538497571, 1.7287740538497571, 1.7287740538497571, 1.7287740538497571, 1.7287740538497571, 1.7277526666650447, 1.7277526666193819, 8.660231268158716, 3.3016814898718323, 3.298450051219061, 8.619364849352163, 7.467432243898388, 12.551961371999628, 7.163870117439305, 5.368828827468749, 2.516182077601695, 2.51289399050763, 2.5152771495161823, 2.8879707951689566, 17.404073177742916, 8.003544177408681, 11.314033315665995, 7.094731012584709, 7.261004913281745, 3.5112942302307983, 15.879427926679481, 5.038159437342425, 7.161979623863759, 4.511775864692307, 4.029921677913931, 4.217764944424481, 3.809075567665737, 4.493487841593031, 4.181997856719501, 4.306334656370612, 4.227470404894746], \"Total\": [143.0, 64.0, 72.0, 33.0, 32.0, 503.0, 28.0, 25.0, 70.0, 28.0, 71.0, 23.0, 14.0, 103.0, 29.0, 29.0, 24.0, 25.0, 51.0, 21.0, 21.0, 21.0, 30.0, 24.0, 99.0, 29.0, 23.0, 22.0, 11.0, 31.0, 11.461993789386481, 7.923987160509425, 7.9238906618187155, 11.445682715103224, 6.154960503480778, 6.154970297689688, 6.154940428931145, 29.932291068243888, 5.27051739728007, 5.270473880562993, 5.270448068667477, 5.270263841270947, 4.386036614836302, 4.386036614836302, 4.3860364879558364, 4.3860364879558364, 4.386036396123858, 4.386027140632339, 4.386023290956365, 4.385991405184731, 9.592340968953122, 4.385908121184578, 4.385687085372592, 4.385868493143803, 8.772270003868362, 8.779405825953042, 8.77906296607667, 14.845868299110457, 4.380106232330171, 3.5015419140084107, 7.905514232436359, 23.33714265531358, 22.716410780756757, 18.027758483190595, 33.11294663895871, 103.3008323698711, 55.478393224324456, 11.193222696361284, 9.619879347331837, 51.35150916372168, 13.114303532723213, 14.771253900290002, 7.021500708058288, 10.501041408038972, 71.27483288019717, 40.72495625759305, 38.962069030413, 38.0194795366197, 17.485319822630427, 32.81515299905742, 15.714074718316057, 13.629039921653728, 19.938590354431966, 47.765503501556815, 503.8687358000344, 70.52837071350302, 21.798890538541073, 60.21609420929832, 30.722826935764363, 15.69617872003924, 29.246397741203317, 57.84990515458947, 18.14844589639627, 35.869768894141984, 64.96530456462588, 12.115870586116626, 8.645204384402415, 7.779627500302175, 7.779542419469139, 6.9131884864394815, 6.913175531555543, 6.913156951358997, 6.913162757553468, 6.913092103719445, 6.913219218717594, 6.04675255505412, 6.046732363532262, 6.046732276408932, 6.046617864041936, 6.046614584666098, 6.04560273924404, 13.821304472692212, 5.180303521737351, 5.180303454375417, 5.18030453097528, 5.180290257765702, 5.180203283942857, 19.0048813947156, 4.313854470786246, 4.313854449651915, 4.313854159764187, 4.313847966311687, 4.313848604469376, 4.31383748298574, 10.354671205825152, 8.634726054461245, 23.741285711956447, 8.621276020764341, 22.18210652195147, 503.8687358000344, 99.9638615878942, 38.75173558689848, 14.612861824930926, 10.261786311706983, 9.35192847914623, 25.805204131624475, 16.28946509454185, 57.84990515458947, 32.65599874202798, 70.52837071350302, 14.762975842900845, 24.149209820941124, 143.05299019383116, 30.176851046454455, 60.21609420929832, 20.78340930889485, 46.83332691731675, 72.51256573990712, 24.063981820028616, 21.583927518261184, 30.722826935764363, 103.3008323698711, 17.302097414980366, 47.765503501556815, 38.0194795366197, 28.22163106698272, 21.378237072111922, 21.378237072111922, 21.378237072111922, 24.811719770816822, 25.593154216309323, 7.691367340076626, 5.980602891827265, 5.981794672247811, 24.77805457453318, 5.125178984635849, 5.125105588659356, 5.1250255676068655, 5.125236694864606, 5.125112345546423, 29.976523410887935, 11.144293115487875, 4.269754835402099, 4.269552832295679, 3.4143307521300597, 3.4143307521300597, 3.4143306431427, 3.414330597706679, 3.4143396386713976, 3.4143737330901387, 3.414375409645773, 3.414379203412625, 3.4143661079312113, 3.4143631285330605, 3.414426914410885, 8.456721468057154, 30.13527638112773, 26.582592729936778, 31.616446748658955, 6.864881213097589, 7.66138775653025, 18.0167653550012, 36.03425092072968, 15.528719144212259, 24.903940995573755, 5.991588501097843, 71.27483288019717, 12.012369189308403, 503.8687358000344, 35.869768894141984, 35.26795651239841, 16.424661526326013, 99.9638615878942, 46.83332691731675, 47.765503501556815, 103.3008323698711, 57.84990515458947, 38.75173558689848, 60.21609420929832, 38.962069030413, 40.72495625759305, 33.076560245931994, 32.22839829316425, 28.835879526963108, 25.44339163611707, 23.7472601723232, 8.48116771504379, 7.633058250958551, 6.784860711493347, 5.936761922393336, 5.936740262143086, 5.936785532786124, 5.9368051126848576, 5.936750695451132, 5.937019697355639, 5.088701492568401, 5.088994596418138, 4.240527446655727, 4.240527402760207, 4.240538627041676, 4.240576370012219, 4.240618335761756, 4.240618335761756, 4.2406401078327605, 4.240394033702366, 4.240394004288729, 8.488377435558153, 12.736589977474807, 3.39241022979369, 3.392410196111651, 3.392410196111651, 143.05299019383116, 22.94059632274207, 72.51256573990712, 12.773622157734152, 10.991091977250349, 503.8687358000344, 8.519080029655637, 8.307576227660789, 30.176851046454455, 11.164787427529323, 9.1627350250723, 16.469686220766423, 35.26795651239841, 99.9638615878942, 18.14844589639627, 60.21609420929832, 55.478393224324456, 25.805204131624475, 22.490588015298197, 38.962069030413, 40.72495625759305, 24.063981820028616, 14.992917954810745, 11.063849699911696, 10.277992770936821, 9.492004794758785, 9.492090287763848, 8.70616705012755, 8.70616705012755, 8.706167050127554, 4.777767240791784, 4.777664106668902, 10.374166128353275, 3.9913714202648576, 3.9914716518726223, 3.2056588981628042, 3.2059485648840105, 3.2062382923042367, 3.2063082605044797, 11.22224906758644, 2.419674448646042, 2.419674471997351, 2.419674504853943, 2.419674504853943, 2.419674504853943, 2.419674504853943, 2.419674504853943, 2.419674504853943, 2.419674504853943, 2.419674504853943, 2.419767762151296, 2.419767762155345, 12.160559465029976, 4.846606060310998, 4.847219978069197, 14.727222711809796, 13.863703606804446, 29.246397741203317, 14.888739882426023, 11.505486095530689, 4.060764717235261, 4.053809465971655, 4.060865510811054, 4.927414459745269, 70.52837071350302, 27.871294140627064, 51.35150916372168, 30.722826935764363, 46.83332691731675, 7.502714300209651, 503.8687358000344, 23.741285711956447, 103.3008323698711, 19.460084706899483, 13.629039921653728, 18.027758483190595, 10.826865471384552, 35.869768894141984, 23.33714265531358, 60.21609420929832, 38.0194795366197], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.4014, -5.7988, -5.799, -5.4482, -6.0784, -6.0786, -6.0787, -4.5143, -6.2543, -6.2545, -6.2547, -6.2551, -6.4677, -6.4677, -6.4677, -6.4677, -6.4677, -6.4678, -6.4678, -6.4679, -5.6858, -6.4686, -6.4689, -6.469, -5.7981, -5.7985, -5.8001, -5.2751, -6.5074, -6.7397, -5.9296, -4.8584, -4.9346, -5.1931, -4.6738, -3.6753, -4.2423, -5.6541, -5.7999, -4.3766, -5.5522, -5.4541, -6.078, -5.7545, -4.2588, -4.7184, -4.7705, -4.7962, -5.3848, -4.986, -5.4744, -5.5737, -5.3347, -4.7983, -3.3825, -4.5813, -5.2946, -4.8412, -5.184, -5.5098, -5.2686, -5.1034, -5.4871, -5.4596, -3.4797, -5.2231, -5.5721, -5.6823, -5.6825, -5.8124, -5.8125, -5.8126, -5.8128, -5.8128, -5.813, -5.9618, -5.962, -5.962, -5.9621, -5.9626, -5.9712, -5.1531, -6.1377, -6.1377, -6.1378, -6.1378, -6.1379, -4.8395, -6.3513, -6.3513, -6.3513, -6.3513, -6.3514, -6.3515, -5.496, -5.6865, -4.7424, -5.7264, -4.8904, -2.255, -3.7558, -4.5186, -5.4039, -5.6819, -5.7436, -5.0845, -5.3838, -4.6336, -5.0083, -4.5969, -5.4839, -5.2736, -4.4805, -5.2228, -4.9538, -5.3771, -5.1023, -4.9827, -5.4336, -5.4872, -5.426, -5.1854, -5.5724, -5.4758, -5.5093, -4.271, -4.5566, -4.5566, -4.5566, -4.4424, -4.4138, -5.6394, -5.9184, -5.9252, -4.5159, -6.0943, -6.0945, -6.0954, -6.0959, -6.0989, -4.3348, -5.3336, -6.3078, -6.3096, -6.5798, -6.5798, -6.5798, -6.5798, -6.58, -6.5802, -6.5803, -6.5803, -6.5805, -6.5807, -6.5808, -5.6764, -4.4394, -4.5786, -4.4493, -5.9183, -5.8307, -5.0725, -4.46, -5.2223, -4.8675, -6.0936, -4.0729, -5.5234, -2.8148, -4.7676, -4.808, -5.3325, -4.2756, -4.8015, -4.8221, -4.423, -4.7499, -5.0267, -5.1181, -5.2489, -5.2835, -3.9195, -3.946, -4.0598, -4.1882, -4.259, -5.3432, -5.4583, -5.5882, -5.7377, -5.7378, -5.7378, -5.7379, -5.7381, -5.7392, -5.9138, -5.9172, -6.1271, -6.1271, -6.1275, -6.1275, -6.1277, -6.1277, -6.1282, -6.1284, -6.1284, -5.4577, -5.0636, -6.3991, -6.3991, -6.3991, -2.6921, -4.5402, -3.5085, -5.1481, -5.3676, -3.1514, -5.7107, -5.7336, -4.9932, -5.6113, -5.7329, -5.4374, -5.1029, -4.7445, -5.4575, -5.0471, -5.3123, -5.5606, -5.6281, -5.5938, -5.6195, -5.6854, -4.1183, -4.4396, -4.5184, -4.6037, -4.6038, -4.6972, -4.6972, -4.6972, -5.3723, -5.3723, -4.6016, -5.5847, -5.585, -5.8572, -5.8582, -5.8588, -5.8595, -4.6391, -6.2311, -6.2311, -6.2311, -6.2311, -6.2311, -6.2311, -6.2311, -6.2311, -6.2311, -6.2311, -6.2317, -6.2317, -4.6198, -5.5841, -5.5851, -4.6245, -4.768, -4.2487, -4.8095, -5.0979, -5.8558, -5.8571, -5.8561, -5.718, -3.9218, -4.6986, -4.3525, -4.8192, -4.796, -5.5225, -4.0135, -5.1615, -4.8097, -5.2718, -5.3848, -5.3392, -5.4411, -5.2759, -5.3477, -5.3184, -5.3369], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.2602, 1.2319, 1.2317, 1.2148, 1.2049, 1.2048, 1.2047, 1.1874, 1.1842, 1.184, 1.1839, 1.1835, 1.1545, 1.1545, 1.1545, 1.1545, 1.1545, 1.1544, 1.1544, 1.1543, 1.1538, 1.1536, 1.1534, 1.1533, 1.1309, 1.1298, 1.1281, 1.1278, 1.1161, 1.1078, 1.1034, 1.0922, 1.043, 1.0156, 0.927, 0.7877, 0.8423, 1.0313, 1.0369, 0.7853, 0.9748, 0.9539, 1.0737, 0.9947, 0.5753, 0.6754, 0.6675, 0.6663, 0.8545, 0.6238, 0.8717, 0.9148, 0.7733, 0.436, -0.5042, 0.2633, 0.7242, 0.1615, 0.4916, 0.8375, 0.4563, -0.0606, 0.715, 0.0612, 1.4471, 1.383, 1.3715, 1.3668, 1.3667, 1.3548, 1.3547, 1.3546, 1.3545, 1.3544, 1.3542, 1.3393, 1.3391, 1.3391, 1.339, 1.3385, 1.3301, 1.3213, 1.3181, 1.3181, 1.3179, 1.3179, 1.3179, 1.3164, 1.2875, 1.2875, 1.2875, 1.2875, 1.2874, 1.2873, 1.2672, 1.2583, 1.191, 1.22, 1.1109, 0.6233, 0.7401, 0.9248, 1.0149, 1.0903, 1.1215, 0.7656, 0.9263, 0.4092, 0.6063, 0.2477, 0.9246, 0.6428, -0.3431, 0.4708, 0.0489, 0.6894, 0.1517, -0.1658, 0.4864, 0.5415, 0.2496, -0.7224, 0.6774, -0.2415, -0.0467, 1.4895, 1.4817, 1.4817, 1.4817, 1.4469, 1.4445, 1.4212, 1.3937, 1.3868, 1.3748, 1.3722, 1.3719, 1.3711, 1.3706, 1.3675, 1.3654, 1.3561, 1.3412, 1.3396, 1.2929, 1.2929, 1.2929, 1.2929, 1.2927, 1.2924, 1.2924, 1.2923, 1.2922, 1.2919, 1.2918, 1.2892, 1.2555, 1.2418, 1.1976, 1.2559, 1.2338, 1.1369, 1.0562, 1.1356, 1.0181, 1.2167, 0.7612, 1.0913, 0.0635, 0.7532, 0.7296, 0.9693, 0.2202, 0.4525, 0.4122, 0.04, 0.2929, 0.4168, -0.1154, 0.1892, 0.1103, 1.6824, 1.6818, 1.6792, 1.676, 1.6741, 1.6196, 1.6098, 1.5977, 1.5818, 1.5817, 1.5817, 1.5816, 1.5813, 1.5803, 1.5598, 1.5563, 1.5288, 1.5288, 1.5285, 1.5285, 1.5282, 1.5282, 1.5277, 1.5276, 1.5276, 1.5043, 1.4926, 1.48, 1.48, 1.48, 1.4453, 1.4275, 1.3084, 1.4051, 1.336, -0.2731, 1.2477, 1.2499, 0.7004, 1.0765, 1.1526, 0.8618, 0.4348, -0.2487, 0.7445, -0.0444, -0.2276, 0.2894, 0.3594, -0.1558, -0.2257, 0.2345, 2.2747, 2.2574, 2.2522, 2.2465, 2.2464, 2.2394, 2.2394, 2.2394, 2.1644, 2.1644, 2.1597, 2.1318, 2.1315, 2.0785, 2.0774, 2.0767, 2.076, 2.0436, 1.9859, 1.9859, 1.9859, 1.9859, 1.9859, 1.9859, 1.9859, 1.9859, 1.9859, 1.9859, 1.9853, 1.9853, 1.9827, 1.9383, 1.9372, 1.7864, 1.7034, 1.4762, 1.5906, 1.5599, 1.8435, 1.8439, 1.8431, 1.7878, 0.9228, 1.0744, 0.8095, 0.8565, 0.458, 1.5628, -1.1352, 0.7719, -0.3467, 0.8604, 1.1037, 0.8695, 1.2775, 0.2448, 0.6029, -0.3157, 0.1256]}, \"token.table\": {\"Topic\": [2, 4, 1, 3, 5, 1, 5, 4, 2, 3, 4, 1, 4, 5, 5, 3, 4, 1, 2, 3, 4, 1, 5, 1, 2, 3, 5, 1, 2, 3, 5, 4, 4, 4, 5, 3, 5, 1, 4, 5, 1, 1, 2, 3, 5, 2, 3, 4, 5, 2, 1, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 5, 2, 2, 4, 2, 4, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 5, 5, 5, 2, 1, 2, 3, 4, 1, 2, 4, 1, 5, 5, 1, 2, 5, 1, 3, 4, 5, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 4, 3, 2, 3, 2, 4, 3, 4, 2, 3, 2, 1, 5, 3, 5, 3, 4, 3, 1, 5, 2, 2, 3, 1, 3, 2, 4, 4, 2, 3, 3, 4, 1, 3, 5, 1, 2, 3, 4, 5, 1, 3, 5, 1, 2, 3, 4, 5, 3, 4, 1, 2, 3, 4, 2, 3, 4, 2, 4, 1, 2, 1, 2, 3, 1, 4, 3, 4, 5, 2, 2, 4, 2, 3, 4, 3, 1, 2, 3, 4, 5, 3, 3, 1, 2, 3, 5, 1, 3, 5, 5, 2, 5, 1, 2, 3, 4, 5, 4, 1, 4, 2, 3, 1, 1, 5, 5, 3, 1, 2, 3, 4, 3, 4, 5, 1, 5, 1, 3, 5, 1, 3, 1, 2, 3, 4, 1, 2, 3, 5, 3, 3, 4, 5, 5, 3, 3, 3, 1, 2, 5, 5, 2, 3, 1, 2, 4, 4, 1, 2, 3, 4, 2, 3, 5, 2, 3, 5, 1, 3, 4, 2, 3, 4, 5, 3, 5, 1, 2, 3, 4, 5, 1, 3, 1, 5, 5, 2, 2, 2, 2, 3, 4, 4, 3, 1, 2, 3, 4, 1, 3, 4, 5, 2, 3, 4, 5, 1, 1, 3, 3, 5, 3, 5, 1, 1, 4, 5, 3, 1, 4, 4, 1, 3, 4, 1, 3, 5, 1, 2, 3, 4, 5, 5, 1, 3, 5, 4, 3, 1, 2, 3, 4, 1, 1, 2, 3, 1, 4, 1, 3, 5, 4, 1, 5, 2, 3, 5, 1, 3, 1, 4, 2, 1, 5, 5, 1, 3, 4, 1, 5, 5, 3, 1, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 2, 3, 1, 1, 2, 3, 4, 5, 1, 4, 3, 4, 1, 2, 2, 1, 2, 3, 4, 5, 1, 1, 3, 4, 5, 3, 5, 2, 2, 4, 1, 5, 4, 1, 2, 3, 1, 3, 2, 4, 2, 4, 5, 1, 2, 3, 4, 5, 2, 1, 3, 4, 5, 2, 2, 2, 4, 5, 1, 2, 3, 5, 1, 4, 5, 2, 1, 3, 4, 5, 1, 2, 3, 4, 1, 5], \"Freq\": [0.8269085482868085, 0.8843270201930687, 0.19910220580414223, 0.7632251222492119, 0.9356555129006782, 0.7147182019884816, 0.1786795504971204, 0.8843270201930687, 0.3329900985361152, 0.6659801970722304, 0.9710125184084808, 0.9119851170832933, 0.9433085624138394, 0.948157858506867, 0.7516213562006533, 0.15702790178038892, 0.7851395089019446, 0.41871221977903245, 0.1884204989005646, 0.33496977582322596, 0.06280683296685487, 0.6603546582691316, 0.29349095923072516, 0.42313814504051167, 0.29294179272035425, 0.03254908808003936, 0.22784361656027552, 0.35446728383325066, 0.29775251841993056, 0.09925083947331019, 0.24103775300661046, 0.9432663365222337, 0.8422099564309813, 0.9433085689571312, 0.8265255993899813, 0.20630382044231713, 0.6189114613269514, 0.6769905972439937, 0.2030971791731981, 0.06769905972439937, 0.8123516049909755, 0.20554895110923224, 0.20554895110923224, 0.3083234266638484, 0.2569361888865403, 0.0869150587551838, 0.2607451762655514, 0.1738301175103676, 0.43457529377591897, 0.9651968811022834, 0.9120118090662718, 0.19882790257881972, 0.3645178213945028, 0.06627596752627324, 0.3645178213945028, 0.48757962519509157, 0.24378981259754579, 0.09142117972407966, 0.060947453149386446, 0.12189490629877289, 0.027581426468534193, 0.19306998527973937, 0.09653499263986969, 0.6757449484790877, 0.11780814503028104, 0.8246570152119673, 0.3155302622910089, 0.2491028386507965, 0.1992822709206372, 0.166068559100531, 0.0664274236402124, 0.5905083105389514, 0.11616556928635108, 0.23233113857270216, 0.06776324875037146, 0.8679095531845064, 0.869172938580313, 0.09657477095336811, 0.82689290205675, 0.8422130292415833, 0.9486812976039071, 0.8567654118313073, 0.07213079768303687, 0.07213079768303687, 0.2885231907321475, 0.5049155837812581, 0.2787862957665483, 0.05575725915330965, 0.47393670280313205, 0.05575725915330965, 0.1115145183066193, 0.2063299528692934, 0.6189898586078801, 0.8265574547270458, 0.9729526205035963, 0.9272450026045866, 0.3653043315615968, 0.06088405526026613, 0.6088405526026613, 0.06088405526026613, 0.17913462419074322, 0.17913462419074322, 0.5374038725722297, 0.8339987106268486, 0.10424983882835608, 0.9188888696872399, 0.9486734646925414, 0.8997958520647371, 0.9337742020730428, 0.6643926993231136, 0.12079867260420248, 0.1509983407552531, 0.03019966815105062, 0.0909827705991203, 0.0909827705991203, 0.7278621647929624, 0.0909827705991203, 0.16075615382524092, 0.43463700849046616, 0.23418797717751144, 0.13892507120699832, 0.03175430199017104, 0.8372292213712974, 0.75896391096002, 0.12649398516000335, 0.8422038293486785, 0.8786495373397718, 0.04030353434735246, 0.9269812899891067, 0.8679184234753397, 0.9685327837021758, 0.8786411658823511, 0.9432763976001126, 0.9079000903661613, 0.8786380055118888, 0.9272450694574841, 0.9120577738756239, 0.8265574547270458, 0.24625292252051845, 0.7387587675615553, 0.7831479349006775, 0.13052465581677958, 0.878640399174335, 0.8123555471792423, 0.9038445271070352, 0.9272464007163366, 0.9651942217108741, 0.8786247517374701, 0.7973204723384706, 0.11390292461978152, 0.8119447728086309, 0.11599211040123297, 0.9432788846006839, 0.8997860115703621, 0.7804706961157419, 0.8878824579961796, 0.12107488063584267, 0.7618292023756498, 0.19045730059391244, 0.9357604900029138, 0.5156543291826031, 0.04910993611262887, 0.24554968056314436, 0.14732980833788661, 0.04910993611262887, 0.8083057021810589, 0.06735880851508824, 0.06735880851508824, 0.2779846251301424, 0.4169769376952136, 0.09266154171004747, 0.18532308342009493, 0.04633077085502373, 0.9368219380734782, 0.9432586673192006, 0.03875187326166091, 0.5037743524015917, 0.19375936630830454, 0.23251123956996544, 0.23476713366206575, 0.11738356683103288, 0.5869178341551644, 0.8682248498113402, 0.07235207081761168, 0.7120984826308862, 0.14241969652617725, 0.2709480827284224, 0.6096331861389505, 0.1354740413642112, 0.797969054408171, 0.11399557920116729, 0.10913771895221966, 0.5456885947610983, 0.21827543790443932, 0.8270473955464058, 0.8268901289537305, 0.7860098737018466, 0.5935218036473194, 0.3354688455397893, 0.07741588743225906, 0.982307377786294, 0.5133197619558758, 0.025665988097793788, 0.2566598809779379, 0.15399592858676273, 0.051331976195587575, 0.8786495256471905, 0.992146766200129, 0.2870336755672448, 0.2511544661213392, 0.179396047229528, 0.2870336755672448, 0.18977464633196, 0.7274694776058467, 0.09488732316598, 0.8265574547270458, 0.7581729236734195, 0.21060358990928318, 0.5842087309323737, 0.07789449745764983, 0.07789449745764983, 0.038947248728824914, 0.214209868008537, 0.9170636159000815, 0.5464584983199019, 0.4250232764710348, 0.9651944223029777, 0.878638436948402, 0.9119850907011388, 0.0963932896030009, 0.8675396064270082, 0.8265574659508121, 0.8786494976002029, 0.6363721809432515, 0.06363721809432515, 0.19091165428297546, 0.1272744361886503, 0.7804839111988671, 0.6018602614023655, 0.2407441045609462, 0.7211101708579818, 0.2218800525716867, 0.2220154351341239, 0.6660463054023718, 0.05550385878353097, 0.25758724611172124, 0.7083649268072334, 0.5504867313675277, 0.18349557712250922, 0.18349557712250922, 0.09174778856125461, 0.410306941257726, 0.034192245104810504, 0.1025767353144315, 0.4444991863625365, 0.8786370292443034, 0.08910869772872268, 0.08910869772872268, 0.7128695818297814, 0.9188888696872403, 0.780451760210007, 0.8358695465087108, 0.910111257269668, 0.4330377112935073, 0.4811530125483414, 0.09623060250966829, 0.8265255993913642, 0.22571161740904686, 0.7523720580301562, 0.2311858443553064, 0.4623716887106128, 0.288982305444133, 0.9674524727502644, 0.4770267235441878, 0.042090593253898925, 0.4770267235441878, 0.8843217650490869, 0.7213020992468122, 0.1352441436087773, 0.1352441436087773, 0.6138937001283562, 0.3069468500641781, 0.06138937001283562, 0.2551891544052477, 0.45366960783155147, 0.2835435048947197, 0.16690064743544542, 0.6676025897417817, 0.2466815493905584, 0.7400446481716751, 0.8277439462137304, 0.11824913517339006, 0.612851202494681, 0.05407510610247184, 0.10815021220494368, 0.14420028293992493, 0.07210014146996246, 0.868627127162485, 0.10022620698028674, 0.24669917602286934, 0.7400975280686081, 0.948166398416649, 0.9272486540757388, 0.867907949481782, 0.925368521585622, 0.9851412292900802, 0.21795422968335262, 0.741044380923399, 0.9929131354562944, 0.8360361138226886, 0.40016739419521447, 0.08892608759893655, 0.26677826279680966, 0.26677826279680966, 0.1942596230291847, 0.6382816185244641, 0.1387568735922748, 0.027751374718454958, 0.16776999884784613, 0.06291374956794231, 0.7759362446712884, 0.7516024819047712, 0.9132198599375161, 0.9596934182764716, 0.9368662614368578, 0.9377507671448297, 0.03907294863103457, 0.982307377786294, 0.9356759312621088, 0.9120200494504086, 0.5510113679753534, 0.38570795758274745, 0.05510113679753535, 0.7804605482054604, 0.8833936575371707, 0.8421733891546647, 0.8843270114128992, 0.07828633003634929, 0.15657266007269857, 0.7045769703271436, 0.873691875697763, 0.0873691875697763, 0.8265574547270458, 0.09003253632900789, 0.4901771422357096, 0.2700976089870236, 0.1400506120673456, 0.010003615147667542, 0.8265574547270458, 0.08973202603673817, 0.8973202603673818, 0.8265574547270458, 0.7860551470432382, 0.7804717250803674, 0.6370977406897799, 0.06370977406897799, 0.19112932220693393, 0.12741954813795597, 0.911994491204783, 0.8834044156779592, 0.8106800326784378, 0.11581143323977683, 0.9487191060237752, 0.9432586673192006, 0.7483576593182946, 0.1760841551337164, 0.0440210387834291, 0.982573406782464, 0.9486859437482601, 0.8265574547270458, 0.7485087183471547, 0.10692981690673639, 0.21385963381347278, 0.7973516111057434, 0.1139073730151062, 0.7276598538568485, 0.207902815387671, 0.867910282120893, 0.39985528969378054, 0.533140386258374, 0.8265574547270458, 0.20077143617103266, 0.602314308513098, 0.20077143617103266, 0.8141527984221296, 0.17140058914150097, 0.8372111487241706, 0.878647210728975, 0.6862735773610031, 0.15250523941355623, 0.07625261970677812, 0.19217084483212798, 0.2775801092019627, 0.34163705747933865, 0.04270463218491733, 0.14946621264721066, 0.1242276671677486, 0.45550144628174494, 0.28986455672474676, 0.1242276671677486, 0.1334377554452208, 0.8673454103939351, 0.812352897662362, 0.1847256720133826, 0.0923628360066913, 0.1847256720133826, 0.1847256720133826, 0.3694513440267652, 0.9119878611332698, 0.9432680020306943, 0.8786494976002029, 0.9432788943649687, 0.911987060669058, 0.9651944097520985, 0.9272450071473228, 0.25929169563746446, 0.3457222608499526, 0.29386392172245973, 0.06914445216999053, 0.034572226084995265, 0.9119851170832933, 0.2686594051335005, 0.13432970256675025, 0.06716485128337513, 0.47015395898362594, 0.24625903484525002, 0.7387771045357501, 0.9652130864243424, 0.6158957846740977, 0.34216432481894316, 0.4058923835896267, 0.6088385753844401, 0.8422115491275571, 0.6290991592709226, 0.11438166532198595, 0.2287633306439719, 0.1456689444373907, 0.7283447221869536, 0.8945070293744076, 0.10523612110287149, 0.867902464853849, 0.9432538244902506, 0.9188888696872403, 0.18373347106600824, 0.42871143248735255, 0.24497796142134431, 0.06124449035533608, 0.06124449035533608, 0.8269089967598963, 0.601847963506238, 0.1504619908765595, 0.20061598783541268, 0.05015399695885317, 0.8268928901426023, 0.8679063230764299, 0.6821424445385469, 0.1948978412967277, 0.09744892064836384, 0.5260461280311939, 0.21041845121247754, 0.13151153200779847, 0.10520922560623877, 0.20370439550658065, 0.13580293033772042, 0.611113186519742, 0.9272462635466131, 0.9119851361778447, 0.982307377786294, 0.8422066069908218, 0.8265574739275873, 0.0831117649172834, 0.37400294212777535, 0.2908911772104919, 0.2493352947518502, 0.9119850907011388, 0.9358450463083675], \"Term\": [\"abierto\", \"acce\", \"access\", \"access\", \"advancements\", \"alibaba\", \"alibaba\", \"allows\", \"alphabet\", \"alphabet\", \"altman\", \"always\", \"ama\", \"amazon\", \"amzn\", \"api\", \"api\", \"app\", \"app\", \"app\", \"app\", \"appeared\", \"appeared\", \"apple\", \"apple\", \"apple\", \"apple\", \"artificial\", \"artificial\", \"artificial\", \"artificial\", \"artificiale\", \"arxivlabs\", \"ask\", \"aten\\u00e7\\u00e3o\", \"authorities\", \"authorities\", \"available\", \"available\", \"available\", \"baidu\", \"big\", \"big\", \"big\", \"big\", \"business\", \"business\", \"business\", \"business\", \"ca\", \"california\", \"ceo\", \"ceo\", \"ceo\", \"ceo\", \"chatbot\", \"chatbot\", \"chatbot\", \"chatbot\", \"chatbot\", \"chatgpt\", \"chatgpt\", \"chatgpt\", \"chatgpt\", \"che\", \"che\", \"china\", \"china\", \"china\", \"china\", \"china\", \"chinese\", \"chinese\", \"chinese\", \"chinese\", \"chino\", \"chips\", \"chips\", \"ch\\u00ednh\", \"cinese\", \"cisco\", \"column\", \"com\", \"com\", \"com\", \"com\", \"company\", \"company\", \"company\", \"company\", \"company\", \"computer\", \"computer\", \"construed\", \"content\", \"contents\", \"cost\", \"cost\", \"cost\", \"cost\", \"could\", \"could\", \"could\", \"country\", \"country\", \"coverage\", \"credit\", \"c\\u00f3digo\", \"daily\", \"data\", \"data\", \"data\", \"data\", \"deep\", \"deep\", \"deep\", \"deep\", \"deepseek\", \"deepseek\", \"deepseek\", \"deepseek\", \"deepseek\", \"deepseekdeepseek\", \"deepseeks\", \"deepseeks\", \"della\", \"demostrado\", \"device\", \"device\", \"devices\", \"di\", \"directamente\", \"directly\", \"donald\", \"downloaded\", \"d\\u00f3lares\", \"early\", \"educational\", \"embargo\", \"embargo\", \"emergence\", \"emergence\", \"europe\", \"everything\", \"exclusive\", \"explicarte\", \"fait\", \"far\", \"february\", \"february\", \"figure\", \"figure\", \"flag\", \"flyer\", \"fraction\", \"framework\", \"framework\", \"free\", \"free\", \"funciones\", \"getty\", \"getty\", \"getty\", \"getty\", \"getty\", \"giant\", \"giant\", \"giant\", \"global\", \"global\", \"global\", \"global\", \"global\", \"going\", \"gold\", \"google\", \"google\", \"google\", \"google\", \"gpt\", \"gpt\", \"gpt\", \"gpu\", \"gpu\", \"group\", \"group\", \"high\", \"high\", \"high\", \"home\", \"home\", \"hong\", \"hong\", \"hong\", \"house\", \"huang\", \"h\\u00e0nh\", \"ia\", \"ia\", \"ia\", \"iab\", \"images\", \"images\", \"images\", \"images\", \"images\", \"im\\u00e1genes\", \"including\", \"industry\", \"industry\", \"industry\", \"industry\", \"information\", \"information\", \"information\", \"informational\", \"inteligencia\", \"inteligencia\", \"intelligence\", \"intelligence\", \"intelligence\", \"intelligence\", \"intelligence\", \"intelligenza\", \"january\", \"january\", \"jensen\", \"jin\", \"jinping\", \"join\", \"join\", \"joining\", \"justin\", \"ki\", \"ki\", \"ki\", \"ki\", \"know\", \"kong\", \"kong\", \"korea\", \"korea\", \"language\", \"language\", \"language\", \"large\", \"large\", \"last\", \"last\", \"last\", \"last\", \"latest\", \"latest\", \"latest\", \"latest\", \"launching\", \"leading\", \"leading\", \"leading\", \"learn\", \"learning\", \"llama\", \"llms\", \"market\", \"market\", \"market\", \"mas\", \"meta\", \"meta\", \"microsoft\", \"microsoft\", \"microsoft\", \"mini\", \"model\", \"model\", \"model\", \"modello\", \"modelo\", \"modelo\", \"modelo\", \"modelos\", \"modelos\", \"modelos\", \"models\", \"models\", \"models\", \"momento\", \"momento\", \"mostly\", \"mostly\", \"na\", \"na\", \"new\", \"new\", \"new\", \"new\", \"new\", \"news\", \"news\", \"newsletter\", \"newsletter\", \"newsletters\", \"ngi\", \"nhng\", \"nvda\", \"nvidia\", \"o1\", \"o1\", \"o3\", \"ollama\", \"one\", \"one\", \"one\", \"one\", \"open\", \"open\", \"open\", \"open\", \"openai\", \"openai\", \"openai\", \"originally\", \"owned\", \"page\", \"parec\\u00eda\", \"part\", \"part\", \"partners\", \"paused\", \"performance\", \"photo\", \"photo\", \"photo\", \"pichai\", \"platform\", \"plus\", \"plusteam\", \"pro\", \"pro\", \"pro\", \"protection\", \"protection\", \"purposes\", \"r1\", \"r1\", \"r1\", \"r1\", \"r1\", \"rating\", \"reasoning\", \"reasoning\", \"recommendation\", \"reddit\", \"reinforcement\", \"release\", \"release\", \"release\", \"release\", \"reporting\", \"researchers\", \"rise\", \"rise\", \"rivals\", \"rush\", \"said\", \"said\", \"said\", \"sam\", \"san\", \"securities\", \"semana\", \"semana\", \"semana\", \"services\", \"services\", \"shows\", \"shows\", \"si\", \"sign\", \"sign\", \"solicitation\", \"source\", \"source\", \"source\", \"south\", \"south\", \"spending\", \"st\", \"start\", \"start\", \"start\", \"startup\", \"startup\", \"startup\", \"startup\", \"startup\", \"stocks\", \"stocks\", \"stocks\", \"stocks\", \"store\", \"store\", \"stories\", \"story\", \"story\", \"story\", \"story\", \"story\", \"success\", \"sulla\", \"sullivan\", \"suo\", \"suspended\", \"table\", \"tariffs\", \"tech\", \"tech\", \"tech\", \"tech\", \"tech\", \"techmeme\", \"technology\", \"technology\", \"technology\", \"technology\", \"temporarily\", \"temporarily\", \"terremoto\", \"th\", \"th\", \"thursday\", \"thursday\", \"tools\", \"top\", \"top\", \"top\", \"trained\", \"trained\", \"trump\", \"trump\", \"tsmc\", \"unsplash\", \"updates\", \"us\", \"us\", \"us\", \"us\", \"us\", \"vamos\", \"via\", \"via\", \"via\", \"via\", \"vn\", \"v\\u00e0\", \"wall\", \"wall\", \"wall\", \"week\", \"week\", \"week\", \"week\", \"weekly\", \"weekly\", \"weekly\", \"wiped\", \"wiz\", \"words\", \"work\", \"works\", \"world\", \"world\", \"world\", \"world\", \"xi\", \"yoyo\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 3, 4, 5, 2]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el781216127847895363773558193\", ldavis_el781216127847895363773558193_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el781216127847895363773558193\", ldavis_el781216127847895363773558193_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el781216127847895363773558193\", ldavis_el781216127847895363773558193_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize LDA results\n",
    "pyLDAvis.enable_notebook()\n",
    "lda_vis = pyLDAvis.lda_model.prepare(lda_model, count_matrix, count_vectorizer)\n",
    "pyLDAvis.display(lda_vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5414e5b-3a1a-4756-bd0d-80be8cd47617",
   "metadata": {},
   "source": [
    "The LDA visualization show five distinct topics, with Topic 1 being the most prevalent and Topics 2 and 5 showing some overlap. The most salient terms include AI-related words like \"openai,\" \"nvidia,\" and \"deepseek,\" alongside technical and business-related terms, indicating a focus on AI companies, technologies, and partnerships. Term frequency analysis highlights \"deepseek\" as the most frequent term. The marginal topic distribution shows the relative importance of different topics within the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460aba72-5854-4391-a614-fd1544457ada",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "The higher coherence score will be selected as the best model as it indicates more interpretable topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34cac8ea-5112-48c1-92a0-e21c432dd43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Scores:\n",
      "NMF: 0.4934\n",
      "LSA: 0.4854\n",
      "LDA: 0.2895\n"
     ]
    }
   ],
   "source": [
    "# Calculate coherence scores for each model\n",
    "def calculate_coherence(model, feature_names, doc_term_matrix):\n",
    "    coherence_scores = []\n",
    "    for topic in model.components_:\n",
    "        top_words = [feature_names[i] for i in topic.argsort()[:-10 - 1:-1]]\n",
    "        word_indices = [list(feature_names).index(word) for word in top_words]\n",
    "        topic_vectors = doc_term_matrix[:, word_indices]\n",
    "        pairwise_similarities = cosine_similarity(topic_vectors.T)\n",
    "        coherence = pairwise_similarities.mean()\n",
    "        coherence_scores.append(coherence)\n",
    "    return coherence_scores\n",
    "\n",
    "nmf_coherence = calculate_coherence(nmf_model, tfidf_vectorizer.get_feature_names_out(), tfidf_matrix)\n",
    "lsa_coherence = calculate_coherence(lsa_model, tfidf_vectorizer.get_feature_names_out(), tfidf_matrix)\n",
    "lda_coherence = calculate_coherence(lda_model, count_vectorizer.get_feature_names_out(), count_matrix)\n",
    "\n",
    "print(\"\\nCoherence Scores:\")\n",
    "print(f\"NMF: {np.mean(nmf_coherence):.4f}\")\n",
    "print(f\"LSA: {np.mean(lsa_coherence):.4f}\")\n",
    "print(f\"LDA: {np.mean(lda_coherence):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27b29aa-e43b-4f09-aa0a-9759dbd0b521",
   "metadata": {},
   "source": [
    "Use the most frequent words to try to discern what semantic groups the unsupervised topics might have identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "947946ed-d656-4a28-910f-a57fb1d5672c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Identified semantic groups:\n",
      "\n",
      "Group_1-3: Topic 2, Topic 4\n",
      "Words: r1, chatgpt, o1, ia\n",
      "\n",
      "Group_2-3: Topic 3, Topic 4\n",
      "Words: artificial\n"
     ]
    }
   ],
   "source": [
    "# Extract top words and their frequencies for each topic\n",
    "n_top_words = 15\n",
    "topic_word_freq = []\n",
    "\n",
    "for topic_idx, topic in enumerate(nmf_model.components_):\n",
    "    top_features_ind = topic.argsort()[:-n_top_words - 1:-1]\n",
    "    top_features = tfidf_vectorizer.get_feature_names_out()[top_features_ind]\n",
    "    weights = topic[top_features_ind]\n",
    "    topic_word_freq.append(dict(zip(top_features, weights)))\n",
    "\n",
    "# Calculate the relevance of each word across all topics\n",
    "word_topic_relevance = {}\n",
    "for topic_idx, word_freq in enumerate(topic_word_freq):\n",
    "    for word, freq in word_freq.items():\n",
    "        if word not in word_topic_relevance:\n",
    "            word_topic_relevance[word] = []\n",
    "        word_topic_relevance[word].append((topic_idx, freq))\n",
    "        \n",
    "# Identify semantic groups based on word relevance across topics\n",
    "threshold = 0.05\n",
    "semantic_groups = {}\n",
    "for word, relevances in word_topic_relevance.items():\n",
    "    relevant_topics = [topic for topic, score in relevances if score >= threshold]\n",
    "    if len(relevant_topics) > 1:\n",
    "        group_name = f\"Group_{'-'.join(map(str, relevant_topics))}\"\n",
    "        if group_name not in semantic_groups:\n",
    "            semantic_groups[group_name] = []\n",
    "        semantic_groups[group_name].append(word)\n",
    "\n",
    "# Display the identified semantic groups with interpretations\n",
    "topic_interpretations = [\n",
    "    \"Topic 1\",\n",
    "    \"Topic 2\",\n",
    "    \"Topic 3\",\n",
    "    \"Topic 4\",\n",
    "    \"Topic 5\"\n",
    "]\n",
    "\n",
    "print(\"\\nIdentified semantic groups:\")\n",
    "for group, words in semantic_groups.items():\n",
    "    topics = [int(t) for t in group.split('_')[1].split('-')]\n",
    "    interpretations = [topic_interpretations[t] for t in topics]\n",
    "    print(f\"\\n{group}: {', '.join(interpretations)}\")\n",
    "    print(f\"Words: {', '.join(words)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971b085a-34d3-4702-9832-c05c7c3bd6a5",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4eeb70a-bc40-49ed-a83a-c9bbff3a4100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels based on the highest probability topic\n",
    "labels = np.argmax(nmf_output, axis=1)\n",
    "\n",
    "def map_to_semantic_class(topic):\n",
    "    if topic in [1, 3]:  # Group_1-3\n",
    "        return \"AI Models and Technologies\"\n",
    "    elif topic in [2, 3]:  # Group_2-3\n",
    "        return \"General Artificial Intelligence\"\n",
    "    else:\n",
    "        return \"Other AI Topics\"\n",
    "\n",
    "# Assign classes based on semantic groups\n",
    "news_df['semantic_class'] = [map_to_semantic_class(label) for label in labels]\n",
    "\n",
    "# New class names dictionary\n",
    "semantic_class_names = {\n",
    "    \"AI Models and Technologies\": 0,\n",
    "    \"General Artificial Intelligence\": 1,\n",
    "    \"Other AI Topics\": 2\n",
    "}\n",
    "\n",
    "# Convert class names to numeric labels for classification\n",
    "news_df['class'] = news_df['semantic_class'].map({v: k for k, v in semantic_class_names.items()})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
