{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "222359ad-938e-4562-b344-74a880b1e77e",
   "metadata": {},
   "source": [
    "# ADS 509 Text Mining Project\n",
    "\n",
    "**Lorena Dorado & Parisa Kamizi** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e633187-7547-4b65-9f38-678770f04ca1",
   "metadata": {},
   "source": [
    "## Load and Explore the Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90ef2292-8fdc-474f-9c62-358d9eab224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import html\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from langdetect import DetectorFactory\n",
    "from typing import List, Dict, Any\n",
    "import random\n",
    "\n",
    "# Text processing\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from langdetect import detect\n",
    "import spacy\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Topic Modeling\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, TruncatedSVD, LatentDirichletAllocation\n",
    "import pyLDAvis\n",
    "import pyLDAvis.lda_model\n",
    "import pyLDAvis.gensim_models\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Download required NLTK resources\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c267811-b3e8-4b4a-99c0-13b0b80de743",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-22 15:05:29,422 - INFO - Setup complete\n"
     ]
    }
   ],
   "source": [
    "# Configure Logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('text_mining.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(\"Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc6195ad-9e5f-4ab2-b72d-92544e785417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up text processing configurations\n",
    "# stop_words = set(stopwords.words('english')) ADD other languages\n",
    "stop_words = set(stopwords.words('english') + \n",
    "                 stopwords.words('spanish') + \n",
    "                 stopwords.words('french') + \n",
    "                 stopwords.words('german'))\n",
    "\n",
    "# Add custom stopwords\n",
    "custom_stopwords = {'ul', 'li', 'ol', 'div', 'span', 'href', 'src', 'img', 'p', 'br', 'nbsp', 'char', 'id', 'av', 'lv'}\n",
    "stop_words.update(custom_stopwords)\n",
    "\n",
    "website_stopwords = ['transparency', 'accept', 'partner', 'click', 'consent', 'cookie', 'policy', 'privacy', 'terms', 'use', 'agreement', 'site']\n",
    "stop_words.update(website_stopwords)\n",
    "\n",
    "punctuation_set = set(string.punctuation) - {\"#\"}  # Keep hashtags\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3b9603-9b4d-487e-8753-19d387fb763d",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3876a3a7-c344-4e66-9dc9-f6e4ccb37c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-22 15:05:29,446 - INFO - Successfully loaded .\\deepseek_20250214.csv\n",
      "2025-02-22 15:05:29,461 - INFO - Successfully loaded .\\deepseek_20250220.csv\n",
      "2025-02-22 15:05:29,461 - INFO - Successfully loaded .\\deepseek_20250222.csv\n",
      "2025-02-22 15:05:29,468 - INFO - Successfully loaded .\\Deepseek_Day_Five.csv\n",
      "2025-02-22 15:05:29,468 - INFO - Successfully loaded .\\Deepseek_Day_Four.csv\n",
      "2025-02-22 15:05:29,468 - INFO - Successfully loaded .\\Deepseek_Day_One.csv\n",
      "2025-02-22 15:05:29,484 - INFO - Successfully loaded .\\Deepseek_Day_Three.csv\n",
      "2025-02-22 15:05:29,484 - INFO - Successfully loaded .\\Deepseek_Day_Two.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1041 entries, 0 to 1040\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype              \n",
      "---  ------       --------------  -----              \n",
      " 0   source       856 non-null    object             \n",
      " 1   date         856 non-null    datetime64[ns, UTC]\n",
      " 2   text         856 non-null    object             \n",
      " 3   title        856 non-null    object             \n",
      " 4   description  828 non-null    object             \n",
      "dtypes: datetime64[ns, UTC](1), object(4)\n",
      "memory usage: 40.8+ KB\n",
      "None\n",
      "\n",
      "First few rows:\n",
      "             source                      date  \\\n",
      "0   Android Central 2025-02-10 18:49:23+00:00   \n",
      "1         MacRumors 2025-02-11 14:54:38+00:00   \n",
      "2  Business Insider 2025-02-07 14:04:28+00:00   \n",
      "3  Business Insider 2025-02-10 07:41:09+00:00   \n",
      "4  Business Insider 2025-02-12 13:06:10+00:00   \n",
      "\n",
      "                                                text  \\\n",
      "0  What you need to know\\r\\n<ul><li>Honor is upgr...   \n",
      "1  Apple in recent months \"passed over\" the Chine...   \n",
      "2  Aiden Gomez is one of the Google Brain researc...   \n",
      "3  Demis Hassabis, cofounder and CEO of Google De...   \n",
      "4  BYD has become the latest automaker to incorpo...   \n",
      "\n",
      "                                               title  \\\n",
      "0  Honor teams up with Gemini and ChatGPT’s bigge...   \n",
      "1  Apple Reportedly 'Passed Over' DeepSeek as App...   \n",
      "2  Aidan Gomez helped spark the generative AI boo...   \n",
      "3  Google's AI lab CEO said DeepSeek is China's '...   \n",
      "4  DeepSeek's AI is the hot new feature for Chine...   \n",
      "\n",
      "                                         description  \n",
      "0  Honor is boosting its AI assistant by teaming ...  \n",
      "1  Apple in recent months \"passed over\" the Chine...  \n",
      "2  The Cohere CEO and former Google Brain member ...  \n",
      "3  \"It's using known techniques, actually many of...  \n",
      "4  Tesla rivals BYD, Geely, and Great Wall have a...  \n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "column_mapping = {\n",
    "    'source_name': 'source',\n",
    "    'publishedAt': 'date',\n",
    "    'content': 'text',\n",
    "    'title': 'title',\n",
    "    'description': 'description'\n",
    "}\n",
    "\n",
    "csv_files = glob.glob(os.path.join('.', '*.csv'))\n",
    "dfs = []\n",
    "\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        temp_df = pd.read_csv(file)\n",
    "        dfs.append(temp_df)\n",
    "        logger.info(f\"Successfully loaded {file}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error reading file {file}: {str(e)}\")\n",
    "\n",
    "if not dfs:\n",
    "    raise ValueError(\"No CSV files were successfully loaded\")\n",
    "\n",
    "news_df = pd.concat(dfs, ignore_index=True)\n",
    "news_df = news_df[column_mapping.keys()].rename(columns=column_mapping)\n",
    "news_df['date'] = pd.to_datetime(news_df['date'])\n",
    "\n",
    "print(\"\\nInitial Dataset Info:\")\n",
    "print(news_df.info())\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(news_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b28dfdc-358b-484e-8e96-ce90554fb9f4",
   "metadata": {},
   "source": [
    "## Data Cleaning with Tokenization and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5cf8811-890e-4733-b356-1e0f2f9c2e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Text processing pipeline functions\n",
    "def validate_text(text):\n",
    "    \"\"\"Check if text is valid\"\"\"\n",
    "    return \"\" if not isinstance(text, str) or pd.isna(text) else text\n",
    "\n",
    "def basic_clean(text):\n",
    "    \"\"\"Basic text cleaning\"\"\"\n",
    "    return (html.unescape(text)\n",
    "            .lower()\n",
    "            .replace('\\n', ' ')\n",
    "            .replace('\\r', ' '))\n",
    "\n",
    "def remove_special_chars(text):\n",
    "    \"\"\"Remove special characters and patterns\"\"\"\n",
    "    return re.sub(r'\\[\\+\\d+ chars\\]|https?://\\S+|â€™|â€\"|[^\\w\\s\\-\\'.,!?]', ' ', text)\n",
    "\n",
    "def remove_num_patterns(text):\n",
    "    \"\"\"Remove date patterns and numbers (including those with commas)\"\"\"\n",
    "    return re.sub(r'\\b\\d{1,4}[-/]\\d{1,2}[-/]\\d{1,4}\\b|\\b\\d{1,3}(,\\d{3})*(\\.\\d+)?\\b|\\b\\d+\\b', '', text)\n",
    "\n",
    "def clean_whitespace(text):\n",
    "    \"\"\"Clean extra whitespace\"\"\"\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "def remove_punct(text):\n",
    "    \"\"\"Remove punctuation\"\"\"\n",
    "    return \"\".join(ch for ch in text if ch not in punctuation_set)\n",
    "\n",
    "def get_tokens(text):\n",
    "    \"\"\"Get tokens without stopwords, lemmatize, remove numbers, and filter short tokens\"\"\"\n",
    "    doc = nlp(text)\n",
    "    return [token.lemma_.lower() for token in doc \n",
    "            if token.is_alpha \n",
    "            and len(token.text) > 2 \n",
    "            and not token.is_stop \n",
    "            and token.lemma_.lower() not in stop_words \n",
    "            and not token.like_num]\n",
    "\n",
    "def detect_lang(text):\n",
    "    \"\"\"Detect language safely\"\"\"\n",
    "    try:\n",
    "        return 'unknown' if len(text.strip()) < 50 else detect(text)\n",
    "    except:\n",
    "        return 'unknown'\n",
    "\n",
    "def remove_duplicates(df):\n",
    "    \"\"\"Remove duplicate articles based on content similarity\"\"\"\n",
    "    df['text_signature'] = df['title'] + df['text'].str[:200]\n",
    "    original_len = len(df)\n",
    "    df = df.drop_duplicates(subset=['text_signature'])\n",
    "    df = df.drop('text_signature', axis=1)\n",
    "    logger.info(f\"Removed {original_len - len(df)} duplicate articles\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c831ffce-1614-4801-a677-c5308505f368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text, steps=None):\n",
    "    if steps is None:\n",
    "        steps = ['validate', 'basic', 'special', 'num_patterns', 'whitespace', 'punct', 'tokens']\n",
    "    \n",
    "    text = validate_text(text)\n",
    "    \n",
    "    pipeline_steps = {\n",
    "        'validate': validate_text,\n",
    "        'basic': basic_clean,\n",
    "        'special': remove_special_chars,\n",
    "        'num_patterns': remove_num_patterns,\n",
    "        'whitespace': clean_whitespace,\n",
    "        'punct': remove_punct,\n",
    "        'tokens': get_tokens\n",
    "    }\n",
    "    \n",
    "    for step in steps:\n",
    "        text = pipeline_steps[step](text)\n",
    "    \n",
    "    return text if isinstance(text, list) else text  # Return tokens as a list if the last step was tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0f2a4ff-c859-4361-ab3d-2d30322a9f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-22 15:05:29,539 - INFO - Removing duplicates...\n",
      "2025-02-22 15:05:29,539 - INFO - Removed 362 duplicate articles\n",
      "2025-02-22 15:05:29,539 - INFO - Processing text...\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 679/679 [00:00<00:00, 21751.90it/s]\n",
      "2025-02-22 15:05:29,586 - INFO - Detecting languages...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 679/679 [00:04<00:00, 148.31it/s]\n",
      "2025-02-22 15:05:34,164 - INFO - Creating cleaned content...\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 679/679 [00:00<00:00, 28668.83it/s]\n",
      "2025-02-22 15:05:34,196 - INFO - Generating tokens...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 679/679 [00:05<00:00, 116.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed DataFrame columns:\n",
      "['source', 'date', 'text', 'title', 'description', 'clean_text', 'language', 'cleaned_content', 'Cleaned_Text', 'Tokens']\n",
      "\n",
      "Sample of processed data:\n",
      "             source                      date  \\\n",
      "0   Android Central 2025-02-10 18:49:23+00:00   \n",
      "1         MacRumors 2025-02-11 14:54:38+00:00   \n",
      "2  Business Insider 2025-02-07 14:04:28+00:00   \n",
      "3  Business Insider 2025-02-10 07:41:09+00:00   \n",
      "4  Business Insider 2025-02-12 13:06:10+00:00   \n",
      "\n",
      "                                          clean_text language  \\\n",
      "0  what you need to know ul li honor is upgrading...       en   \n",
      "1  apple in recent months passed over the chinese...       en   \n",
      "2  aiden gomez is one of the google brain researc...       en   \n",
      "3  demis hassabis, cofounder and ceo of google de...       en   \n",
      "4  byd has become the latest automaker to incorpo...       en   \n",
      "\n",
      "                                              Tokens  \n",
      "0  [need, know, ullihonor, upgrade, yoyo, assista...  \n",
      "1  [apple, recent, month, pass, chinese, artifici...  \n",
      "2  [aiden, gomez, google, brain, researcher, coau...  \n",
      "3  [demis, hassabis, cofounder, ceo, google, deep...  \n",
      "4  [byd, late, automaker, incorporate, deepseek, ...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "logger.info(\"Removing duplicates...\")\n",
    "news_df = remove_duplicates(news_df)\n",
    "\n",
    "# Process text\n",
    "logger.info(\"Processing text...\")\n",
    "tqdm.pandas()\n",
    "news_df['clean_text'] = news_df['text'].progress_apply(\n",
    "    lambda x: process_text(x, ['validate', 'basic', 'special', 'num_patterns', 'whitespace']))\n",
    "\n",
    "# Detect languages\n",
    "logger.info(\"Detecting languages...\")\n",
    "news_df['language'] = news_df['clean_text'].progress_apply(detect_lang)\n",
    "\n",
    "# Create cleaned content\n",
    "logger.info(\"Creating cleaned content...\")\n",
    "news_df['cleaned_content'] = news_df['text'].progress_apply(\n",
    "    lambda x: process_text(x, ['validate', 'basic', 'punct', 'whitespace']))\n",
    "\n",
    "# Generate tokens\n",
    "logger.info(\"Generating tokens...\")\n",
    "def get_cleaned_text_and_tokens(text):\n",
    "    cleaned = process_text(text, ['validate', 'basic', 'punct', 'whitespace'])\n",
    "    tokens = get_tokens(cleaned)\n",
    "    return ' '.join(tokens), tokens\n",
    "\n",
    "temp_results = news_df['text'].progress_apply(get_cleaned_text_and_tokens)\n",
    "news_df['Cleaned_Text'] = temp_results.apply(lambda x: x[0])\n",
    "news_df['Tokens'] = temp_results.apply(lambda x: x[1])\n",
    "\n",
    "# Display processed data sample\n",
    "print(\"\\nProcessed DataFrame columns:\")\n",
    "print(news_df.columns.tolist())\n",
    "print(\"\\nSample of processed data:\")\n",
    "print(news_df[['source', 'date', 'clean_text', 'language', 'Tokens']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea86121-29d9-400a-8125-db390416df01",
   "metadata": {},
   "source": [
    "## Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1070262e-5c02-482c-b99c-fea3b6e5dcd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Descriptive Statistics for 'News Articles':\n",
      "--------------------------------------------------\n",
      "Total documents: 679\n",
      "\n",
      "Token-level Statistics:\n",
      "Total tokens: 10,904\n",
      "Unique tokens: 4,327\n",
      "Total characters: 72,706\n",
      "Lexical diversity: 0.397\n",
      "\n",
      "Top 10 most frequent tokens:\n",
      "deepseek: 502\n",
      "openai: 149\n",
      "model: 121\n",
      "chinese: 110\n",
      "artificial: 81\n",
      "chatgpt: 76\n",
      "nvidia: 67\n",
      "tech: 66\n",
      "new: 64\n",
      "app: 62\n"
     ]
    }
   ],
   "source": [
    "def descriptive_stats_all(df: pd.DataFrame, tokens_col: str = 'Tokens', \n",
    "                         text_col: str = 'text', title: str = \"Dataset\",\n",
    "                         num_tokens: int = 5, plot: bool = True) -> Dict[str, Any]:\n",
    "\n",
    "    # Initialize results dictionary\n",
    "    stats = {}\n",
    "    \n",
    "    # Get all tokens\n",
    "    all_tokens = [token for tokens in df[tokens_col] for token in tokens]\n",
    "    token_counts = Counter(all_tokens)\n",
    "    \n",
    "    # Basic token statistics\n",
    "    stats['total_tokens'] = len(all_tokens)\n",
    "    stats['unique_tokens'] = len(set(all_tokens))\n",
    "    stats['total_characters'] = len(''.join(all_tokens))\n",
    "    stats['lexical_diversity'] = stats['unique_tokens'] / stats['total_tokens'] if stats['total_tokens'] > 0 else 0\n",
    "    \n",
    "    # Document statistics\n",
    "    stats['total_documents'] = len(df)\n",
    "    \n",
    "    # Token length statistics\n",
    "    token_lengths = [len(token) for token in all_tokens]\n",
    "\n",
    "    # Top tokens\n",
    "    stats['top_tokens'] = token_counts.most_common(num_tokens)\n",
    "    \n",
    "    # Print results if verbose\n",
    "    print(f\"\\nDescriptive Statistics for '{title}':\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Total documents: {stats['total_documents']:,}\")\n",
    "    \n",
    "    print(f\"\\nToken-level Statistics:\")\n",
    "    print(f\"Total tokens: {stats['total_tokens']:,}\")\n",
    "    print(f\"Unique tokens: {stats['unique_tokens']:,}\")\n",
    "    print(f\"Total characters: {stats['total_characters']:,}\")\n",
    "    print(f\"Lexical diversity: {stats['lexical_diversity']:.3f}\")\n",
    "    \n",
    "    print(f\"\\nTop {num_tokens} most frequent tokens:\")\n",
    "    for token, count in stats['top_tokens']:\n",
    "        print(f\"{token}: {count:,}\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "stats = descriptive_stats_all(news_df, tokens_col='Tokens', text_col='text',\n",
    "                              title=\"News Articles\", num_tokens=10, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed838cc1-ea42-4851-8714-9121aa5c79c0",
   "metadata": {},
   "source": [
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fd8de81-577d-4be1-a7b7-17d97af2e3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=list(stop_words), max_features=5000, max_df=0.95, min_df=2)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(news_df['clean_text'])\n",
    "\n",
    "# Create Count vectorizer\n",
    "count_vectorizer = CountVectorizer(stop_words=list(stop_words), max_features=5000, max_df=0.95, min_df=2)\n",
    "count_matrix = count_vectorizer.fit_transform(news_df['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "556be751-af49-467f-9389-2dbf66c217ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display topics\n",
    "def display_topics(model, features, no_top_words=5):\n",
    "    for topic, words in enumerate(model.components_):\n",
    "        total = words.sum()\n",
    "        largest = words.argsort()[::-1] # invert sort order\n",
    "        print(\"\\nTopic %02d\" % topic)\n",
    "        for i in range(0, no_top_words):\n",
    "            print(\"  %s (%2.2f)\" % (features[largest[i]], abs(words[largest[i]]*100.0/total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a271b3a8-e155-42d3-89d6-d0ccdde8a312",
   "metadata": {},
   "source": [
    "## NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "015a4a5c-39d0-4db2-ada9-8a47ac537c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF Topics:\n",
      "\n",
      "Topic 00\n",
      "  iab (9.55)\n",
      "  words (9.55)\n",
      "  partners (9.55)\n",
      "  device (9.29)\n",
      "  framework (9.26)\n",
      "\n",
      "Topic 01\n",
      "  deepseek (20.24)\n",
      "  r1 (6.16)\n",
      "  chatgpt (2.73)\n",
      "  nvidia (1.99)\n",
      "  bloomberg (1.12)\n",
      "\n",
      "Topic 02\n",
      "  chinese (1.80)\n",
      "  model (1.38)\n",
      "  intelligence (1.14)\n",
      "  tech (1.09)\n",
      "  app (1.08)\n",
      "\n",
      "Topic 03\n",
      "  openai (9.51)\n",
      "  chatgpt (3.40)\n",
      "  o3 (3.16)\n",
      "  altman (3.15)\n",
      "  mini (3.11)\n",
      "\n",
      "Topic 04\n",
      "  weekly (5.24)\n",
      "  coverage (4.91)\n",
      "  learn (4.91)\n",
      "  updates (4.91)\n",
      "  newsletters (4.89)\n"
     ]
    }
   ],
   "source": [
    "# Fit NMF model\n",
    "n_topics = 5\n",
    "nmf_model = NMF(n_components=n_topics, random_state=42)\n",
    "nmf_output = nmf_model.fit_transform(tfidf_matrix)\n",
    "\n",
    "# Display the topics\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "print(\"NMF Topics:\")\n",
    "display_topics(nmf_model, tfidf_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5e293b-af35-49ed-9dda-dd00f0d6d348",
   "metadata": {},
   "source": [
    "## LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a316060-8177-4ae6-8877-ce4c56b0c931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSA Topics:\n",
      "\n",
      "Topic 00\n",
      "  partners (5.05)\n",
      "  words (5.05)\n",
      "  iab (5.05)\n",
      "  device (4.92)\n",
      "  part (4.91)\n",
      "\n",
      "Topic 01\n",
      "  deepseek (7.32)\n",
      "  r1 (2.44)\n",
      "  openai (2.14)\n",
      "  chatgpt (1.72)\n",
      "  model (1.01)\n",
      "\n",
      "Topic 02\n",
      "  deepseek (2.26)\n",
      "  r1 (0.82)\n",
      "  chatgpt (0.58)\n",
      "  flyer (0.26)\n",
      "  gpu (0.21)\n",
      "\n",
      "Topic 03\n",
      "  openai (38.15)\n",
      "  o3 (14.60)\n",
      "  mini (14.35)\n",
      "  chatgpt (13.67)\n",
      "  altman (13.33)\n",
      "\n",
      "Topic 04\n",
      "  weekly (16.76)\n",
      "  coverage (15.63)\n",
      "  learn (15.63)\n",
      "  updates (15.63)\n",
      "  newsletters (15.60)\n"
     ]
    }
   ],
   "source": [
    "# Fit LSA model\n",
    "lsa_model = TruncatedSVD(n_components=n_topics, random_state=42)\n",
    "lsa_output = lsa_model.fit_transform(tfidf_matrix)\n",
    "\n",
    "print(\"\\nLSA Topics:\")\n",
    "display_topics(lsa_model, tfidf_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c347b6-66e0-408a-97f7-0370e330c14f",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e830e45-0f4a-4823-b223-0de5362d0ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LDA Topics:\n",
      "\n",
      "Topic 00\n",
      "  deepseek (3.33)\n",
      "  chinese (2.63)\n",
      "  new (1.34)\n",
      "  model (1.30)\n",
      "  intelligence (1.21)\n",
      "\n",
      "Topic 01\n",
      "  deepseek (2.24)\n",
      "  artificial (1.60)\n",
      "  daily (1.56)\n",
      "  latest (1.42)\n",
      "  intelligence (1.27)\n",
      "\n",
      "Topic 02\n",
      "  deepseek (10.45)\n",
      "  nvidia (3.07)\n",
      "  r1 (2.47)\n",
      "  openai (1.55)\n",
      "  ia (1.24)\n",
      "\n",
      "Topic 03\n",
      "  deepseek (6.27)\n",
      "  model (1.81)\n",
      "  r1 (1.64)\n",
      "  including (1.41)\n",
      "  store (1.31)\n",
      "\n",
      "Topic 04\n",
      "  openai (6.24)\n",
      "  deepseek (3.86)\n",
      "  chatgpt (2.79)\n",
      "  mini (1.99)\n",
      "  o3 (1.93)\n"
     ]
    }
   ],
   "source": [
    "# Fit LDA model\n",
    "lda_model = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n",
    "lda_output = lda_model.fit_transform(count_matrix)\n",
    "\n",
    "print(\"\\nLDA Topics:\")\n",
    "display_topics(lda_model, count_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "154debfd-033f-49ce-9625-0a7856a4579c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el493227892989310722249166097\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el493227892989310722249166097_data = {\"mdsDat\": {\"x\": [-0.11399390063798069, 0.06579325753292428, -0.027047335469999986, 0.17413214099682237, -0.09888416242176608], \"y\": [-0.04799036542447143, 0.1548921155447363, 0.07467791459151807, -0.11573294286707997, -0.06584672184470297], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [26.338136299653392, 23.291583355041286, 21.725059197854826, 18.28395488790661, 10.361266259543887]}, \"tinfo\": {\"Term\": [\"openai\", \"nvidia\", \"mini\", \"o3\", \"deepseek\", \"chatgpt\", \"altman\", \"sam\", \"including\", \"di\", \"latest\", \"model\", \"chinese\", \"daily\", \"part\", \"store\", \"artificial\", \"r1\", \"device\", \"partners\", \"iab\", \"words\", \"access\", \"intelligence\", \"framework\", \"inteligencia\", \"o1\", \"meta\", \"exclusive\", \"ia\", \"page\", \"february\", \"platform\", \"researchers\", \"free\", \"stories\", \"baidu\", \"everything\", \"credit\", \"cisco\", \"rivals\", \"sales\", \"protection\", \"jinping\", \"xi\", \"always\", \"techmeme\", \"wiz\", \"suspended\", \"reporting\", \"country\", \"performance\", \"success\", \"early\", \"home\", \"services\", \"giant\", \"watchdog\", \"south\", \"column\", \"news\", \"korea\", \"said\", \"chinese\", \"data\", \"top\", \"getty\", \"via\", \"shows\", \"new\", \"images\", \"available\", \"intelligence\", \"week\", \"appeared\", \"app\", \"model\", \"chatbot\", \"release\", \"get\", \"artificial\", \"deepseek\", \"latest\", \"china\", \"apple\", \"tech\", \"last\", \"startup\", \"industry\", \"nvidia\", \"donald\", \"c\\u00f3digo\", \"flyer\", \"chino\", \"v\\u00e0\", \"nhng\", \"si\", \"devices\", \"tsmc\", \"inteligencia\", \"nvda\", \"huang\", \"vn\", \"abierto\", \"ch\\u00ednh\", \"gpu\", \"trump\", \"table\", \"jensen\", \"terremoto\", \"ca\", \"atenci\\u00f3n\", \"mercado\", \"house\", \"c\\u00f3mo\", \"contents\", \"tariffs\", \"d\\u00f3lares\", \"explicarte\", \"figure\", \"rise\", \"modelo\", \"ia\", \"deepseek\", \"r1\", \"modelos\", \"chips\", \"th\", \"wall\", \"artificial\", \"us\", \"openai\", \"tech\", \"google\", \"high\", \"microsoft\", \"china\", \"chatgpt\", \"stocks\", \"startup\", \"ceo\", \"apple\", \"chinese\", \"global\", \"app\", \"chatbot\", \"including\", \"iab\", \"partners\", \"words\", \"large\", \"part\", \"device\", \"language\", \"llms\", \"ollama\", \"llama\", \"framework\", \"pichai\", \"reinforcement\", \"know\", \"learning\", \"fraction\", \"reasoning\", \"store\", \"going\", \"parec\\u00eda\", \"storm\", \"justin\", \"sullivan\", \"demostrado\", \"capabilities\", \"europe\", \"jin\", \"impressive\", \"directamente\", \"access\", \"meta\", \"headlines\", \"information\", \"trained\", \"open\", \"momento\", \"emergence\", \"model\", \"cost\", \"source\", \"company\", \"deepseek\", \"alphabet\", \"r1\", \"models\", \"world\", \"tech\", \"recently\", \"chinese\", \"china\", \"startup\", \"app\", \"ia\", \"openai\", \"mini\", \"o3\", \"altman\", \"sam\", \"di\", \"artificiale\", \"intelligenza\", \"modello\", \"arxivlabs\", \"cinese\", \"work\", \"tools\", \"della\", \"plus\", \"reddit\", \"h\\u00e0nh\", \"flag\", \"suo\", \"directly\", \"sulla\", \"gold\", \"rush\", \"event\", \"ama\", \"ask\", \"unsplash\", \"che\", \"api\", \"plusteam\", \"acce\", \"openai\", \"o1\", \"chatgpt\", \"deep\", \"illustration\", \"deepseek\", \"ceo\", \"photo\", \"kong\", \"could\", \"models\", \"january\", \"china\", \"one\", \"new\", \"google\", \"images\", \"getty\", \"world\", \"source\", \"open\", \"daily\", \"exclusive\", \"content\", \"newsletters\", \"amazon\", \"coverage\", \"learn\", \"updates\", \"janus\", \"7b\", \"deepseekdeepseek\", \"join\", \"amzn\", \"originally\", \"anselmo\", \"screen\", \"yoyo\", \"passada\", \"advancements\", \"funciones\", \"paused\", \"works\", \"joining\", \"construed\", \"educational\", \"informational\", \"purposes\", \"rating\", \"recommendation\", \"securities\", \"leading\", \"newsletter\", \"spending\", \"authorities\", \"pro\", \"business\", \"weekly\", \"com\", \"technology\", \"latest\", \"artificial\", \"intelligence\", \"industry\", \"apple\", \"startup\", \"deepseek\", \"modelo\", \"chinese\", \"week\", \"big\", \"company\", \"r1\"], \"Freq\": [143.0, 64.0, 33.0, 32.0, 502.0, 72.0, 28.0, 25.0, 28.0, 23.0, 29.0, 70.0, 103.0, 15.0, 25.0, 29.0, 70.0, 99.0, 24.0, 21.0, 21.0, 21.0, 30.0, 51.0, 24.0, 24.0, 22.0, 26.0, 11.0, 38.0, 10.802163433714343, 8.144051808900826, 7.259724756419639, 7.257185933698147, 9.627297497244895, 5.48910429734064, 5.4880186858107605, 5.476365583115931, 4.602954803092293, 4.6022797436640985, 4.598789933577937, 5.3129303507251855, 9.770838932465487, 3.718772147202567, 3.718772147202567, 3.718770251516181, 3.718770251516181, 3.7187684296218895, 3.718560095763501, 3.7181572711818567, 8.131611831513345, 3.7137736675235176, 3.713771348888973, 3.7126250193193173, 7.264690260696552, 7.262434138025653, 12.27873497048455, 3.6068118636589848, 19.20439929160183, 2.8333472597187073, 23.44564908776242, 13.777887361212704, 16.588987707460483, 61.976643079553085, 21.64214829941542, 12.418794206361452, 25.398699550981675, 13.482263840835627, 7.251912962551116, 31.531470126856554, 23.36462529902179, 10.314210501018449, 28.496219604146663, 21.71107471674258, 9.41496877653014, 23.264771605521975, 30.70081117595548, 17.087440056882066, 10.23164207382797, 8.547120279254058, 25.25224952112631, 78.53271128529816, 13.915085748701541, 17.821192069689744, 13.154137321533396, 14.466096513333643, 10.041703879424542, 11.453676708789231, 9.90620508986552, 64.06666219584889, 11.400059213243676, 7.0823409996701905, 7.082158652613423, 6.219058697449245, 6.219006762959313, 6.218669364806949, 6.21803757020968, 6.216048149086644, 6.214121951320248, 21.573149821741826, 7.741136229135339, 5.3557519022530125, 5.354939367269152, 5.354844714040955, 5.354845460035437, 12.164032906731043, 16.487200902792654, 4.491920033975552, 4.4919185219375715, 4.491456542681524, 4.491358230008699, 4.4890288946334, 5.981889300784366, 5.1651799177981035, 4.365596408522972, 3.628087837327009, 3.6280872911139648, 3.6280807651573466, 3.627847208325398, 7.0848993825213435, 7.081751177243067, 15.91958060892016, 25.94147166954751, 218.08989252010127, 51.57188591193666, 11.462468631213829, 7.489756847959282, 9.375055082482632, 7.085178142625275, 23.705687209551517, 13.951249355411019, 32.27437630629065, 17.988412424367525, 11.655882779728389, 8.660341545801515, 9.29781002572051, 15.850803946469204, 16.378775262496447, 10.061801351069798, 12.313002012573918, 10.297528167272379, 9.432622424827406, 12.68448869028545, 8.355414346723684, 9.098739698238274, 8.537178802317554, 27.407191258270625, 20.59960202325199, 20.59960202325199, 20.59960202325199, 14.638594873055924, 24.01238523451036, 23.089171135849654, 16.285152715947596, 6.977132188397157, 5.277571915750789, 5.274327252420762, 21.455637180097195, 4.426356221181644, 4.425044817626798, 4.421034291925921, 4.419545885827317, 4.415270238693389, 9.455154057623105, 25.417105744956753, 3.574717604000465, 3.571127717622403, 4.180279654687297, 2.723908951290735, 2.723908951290735, 2.7239040572819317, 2.7227160023845105, 2.722481020948379, 2.7220787998778238, 2.7218627038585366, 2.720924479770461, 23.161136801117674, 20.273102282378588, 5.2656134536940575, 22.311235625020252, 5.279161913907449, 23.60899160810409, 4.428936314127331, 5.43247418379748, 35.15624565600969, 10.2551252708412, 14.070443468292936, 18.49997806592936, 122.11450867242834, 7.833810508918058, 31.914511210568723, 15.899847424590789, 10.714837953680139, 17.563313498287787, 7.6894388882517735, 19.381284844092356, 12.30819411985178, 11.164146066410307, 10.942878611630414, 9.661729830073094, 8.678884907568483, 32.53020197211057, 31.67942628133865, 28.271607592838247, 24.864521343107725, 23.160112239682256, 7.827995420655609, 6.9688973734033, 6.131564710466739, 5.2802616092714105, 5.279848410374389, 5.2797190227476065, 5.278028462091302, 5.278064705397582, 5.273007866944508, 4.427254759766265, 4.4107951234033855, 3.576949710022681, 3.576758106524846, 3.5757119405776234, 3.5753484007918623, 3.5747954697102142, 3.5747954697102142, 3.573193423716611, 3.5718805490220062, 3.5718785232840147, 3.5599073269459125, 6.958873791254645, 10.35383682379691, 2.7252951923700772, 2.725293312148279, 102.20820400912346, 17.200155305850224, 45.71756902914697, 7.642406335083353, 6.925485511889866, 63.218065395947576, 11.23925098878332, 8.312826344537838, 5.298479950862519, 6.094744242704798, 11.174535637037382, 7.233649004724788, 11.344456592874419, 7.0707208440838825, 8.765897710426904, 7.061909041680817, 6.909459943414088, 6.792844694695035, 5.8913654585748265, 5.886032007724405, 5.687847303905864, 14.47308393722764, 10.495668076555532, 9.699942305650902, 8.906986713547223, 8.90611440750446, 8.111982218549347, 8.111982218549347, 8.111982218549347, 4.9264899628506065, 4.135140641366521, 4.131878127318999, 8.925703710366205, 3.3395725795718487, 3.3382738919009434, 2.545029252909485, 2.545029112464382, 2.5432300612825722, 2.543230023495034, 2.539267774895936, 2.539136495377082, 2.538314068851305, 1.749707193611776, 1.7497069146656083, 1.749706560773403, 1.749706560773403, 1.749706560773403, 1.749706560773403, 1.749706560773403, 1.749706560773403, 1.749706560773403, 8.082369109335234, 8.591235689940163, 3.3474176694546625, 3.3363188200936404, 7.739491569256074, 7.028516952095509, 8.746971788410761, 7.917439790984177, 7.62932938795811, 13.182984253904065, 14.835412245677169, 11.786499881267021, 8.128162834601444, 7.811069067829634, 7.991783921710598, 20.797665158275162, 5.541355336719548, 9.025693804254422, 5.277787000351873, 4.522802370238974, 4.820997527567878, 4.853475240015763], \"Total\": [143.0, 64.0, 33.0, 32.0, 502.0, 72.0, 28.0, 25.0, 28.0, 23.0, 29.0, 70.0, 103.0, 15.0, 25.0, 29.0, 70.0, 99.0, 24.0, 21.0, 21.0, 21.0, 30.0, 51.0, 24.0, 24.0, 22.0, 26.0, 11.0, 38.0, 11.47458012747386, 8.81817696397791, 7.932857122324636, 7.932757577553427, 10.577953469550364, 6.161995644479886, 6.161974025761786, 6.161524042416878, 5.27658116465573, 5.276537886966054, 5.276247897886634, 6.15754214054698, 11.43477435537707, 4.391187563058287, 4.391187563058287, 4.391187443865852, 4.391187443865852, 4.391187343639528, 4.391179377999973, 4.391149425326921, 9.612204492126105, 4.390995031968613, 4.390994122960272, 4.390739200214844, 8.78467364191382, 8.784179888336553, 14.8691196595489, 4.379794617230653, 23.464258560189304, 3.5057634309133494, 29.715199629897327, 18.14003553935158, 22.671475902122097, 103.240371878282, 33.120479063774376, 17.527178885059925, 40.91856085016855, 20.091754660449485, 9.635869760194442, 55.482863384334244, 39.133239931993856, 14.806445290178514, 51.41007287855009, 38.01063263031434, 13.719581063131741, 47.781592560950514, 70.93180318630904, 32.88849970173985, 15.722113429417588, 12.130507863265409, 70.93051652716366, 502.75284303205046, 29.407798145289057, 60.30187956321472, 30.740893974003438, 57.663433704926405, 21.710793216746847, 46.879725078573095, 28.00595695476165, 64.77374822838118, 12.079348517477085, 7.760132995082582, 7.760078260723955, 6.896310703209892, 6.896310332509242, 6.896305571955087, 6.896272840584501, 6.896220780976829, 6.896389764442503, 24.02056974994896, 8.62102648773843, 6.032485987603053, 6.032474601914215, 6.03246976300186, 6.032473268363301, 13.793358028339005, 18.964275973334395, 5.1686535871715655, 5.168653537293499, 5.168664794978036, 5.168645719220973, 5.168611261178431, 6.8926535730852585, 6.029695223942308, 5.1668094882037625, 4.304821175362528, 4.304821160294905, 4.304820940535173, 4.304817679715974, 8.611827307440036, 8.611470322198281, 21.98162787904612, 38.68063813233619, 502.75284303205046, 99.39899584459552, 16.33623145156447, 10.261289852735676, 14.605720432623956, 10.258863934790735, 70.93051652716366, 32.6218387180233, 143.52507865694218, 57.663433704926405, 25.755742979693927, 14.731207347272626, 17.35525412794749, 60.30187956321472, 72.54472218559141, 24.094188402112636, 46.879725078573095, 30.178327962571952, 30.740893974003438, 103.240371878282, 21.656413441562922, 47.781592560950514, 32.88849970173985, 28.088712418875417, 21.278860326837698, 21.278860326837698, 21.278860326837698, 15.320359095325612, 25.479788823847937, 24.69729591749139, 17.814497901950038, 7.659287915850268, 5.956833735620345, 5.9569296390451125, 24.68504949630355, 5.105610160850668, 5.105544203187064, 5.10550200312524, 5.105719607871048, 5.105694878515656, 11.1014819604505, 29.845922419070302, 4.2544030341636265, 4.25444536969134, 5.109248452525056, 3.4031627631730172, 3.4031627631730172, 3.403162679761758, 3.40321048766997, 3.403194339659042, 3.403236024176449, 3.403244701561992, 3.4032066478184326, 30.02986469254555, 26.466583860057103, 6.808633678751421, 31.564866276033413, 6.8421230987408395, 35.84478809376274, 5.969373465937641, 7.62037106334778, 70.93180318630904, 16.35261467888969, 24.85617942481087, 35.75879593003011, 502.75284303205046, 11.96557677811543, 99.39899584459552, 35.19784729224018, 23.93497650074807, 57.663433704926405, 13.828596727185014, 103.240371878282, 60.30187956321472, 46.879725078573095, 47.781592560950514, 38.68063813233619, 143.52507865694218, 33.21245489908483, 32.36075206441359, 28.95410201534752, 25.547450766444577, 23.84439088940342, 8.514665414823236, 7.6633058721974265, 6.811092066120663, 5.959427701044139, 5.9594326473678265, 5.9594491020573015, 5.959423656120366, 5.959486491045777, 5.959619337605238, 5.107825110735546, 5.108026002321306, 4.256115696472896, 4.256115552102007, 4.256115021634641, 4.256161485422176, 4.256196138744927, 4.256196138744927, 4.256206550470011, 4.255972114243064, 4.2559720702709445, 4.255905083423425, 8.549137630657508, 12.771821967672668, 3.404459715088917, 3.404459685422996, 143.52507865694218, 22.990051661146282, 72.54472218559141, 11.025420394591272, 11.787497407730832, 502.75284303205046, 30.178327962571952, 17.96470198717599, 8.350770371469414, 11.171747653761999, 35.19784729224018, 16.146104195219632, 60.30187956321472, 22.445332164249802, 55.482863384334244, 25.755742979693927, 39.133239931993856, 40.91856085016855, 23.93497650074807, 24.85617942481087, 35.84478809376274, 15.165486648912056, 11.188964615140652, 10.393575069295885, 9.598094027805768, 9.598183177777065, 8.802740426909706, 8.802740426909706, 8.802740426909706, 5.621777961331785, 4.826142951911564, 4.826422406267648, 10.481381399699833, 4.030857909291125, 4.030961035078675, 3.2354600696887874, 3.2354600799177744, 3.2355865794566725, 3.2355874177592434, 3.2359828010964695, 3.235985903732953, 3.236220645281712, 2.4401373465423912, 2.4401373677897786, 2.440137396685179, 2.440137396685179, 2.440137396685179, 2.440137396685179, 2.440137396685179, 2.440137396685179, 2.440137396685179, 11.359005487893295, 12.28462828958459, 4.894254400935596, 4.8830352647423725, 12.235803082945361, 11.450669236610572, 14.838921142531797, 13.939878244762236, 14.907316877862991, 29.407798145289057, 70.93051652716366, 51.41007287855009, 28.00595695476165, 30.740893974003438, 46.879725078573095, 502.75284303205046, 21.98162787904612, 103.240371878282, 38.01063263031434, 19.4210194558732, 35.75879593003011, 99.39899584459552], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.3867, -5.6692, -5.7841, -5.7845, -5.5019, -6.0637, -6.0639, -6.066, -6.2398, -6.2399, -6.2407, -6.0963, -5.4871, -6.4531, -6.4531, -6.4531, -6.4531, -6.4531, -6.4531, -6.4533, -5.6707, -6.4544, -6.4544, -6.4547, -5.7835, -5.7838, -5.2586, -6.4837, -4.8113, -6.725, -4.6118, -5.1434, -4.9577, -3.6397, -4.6918, -5.2473, -4.5318, -5.1651, -5.7852, -4.3155, -4.6153, -5.433, -4.4167, -4.6887, -5.5242, -4.6195, -4.3422, -4.9281, -5.441, -5.6209, -4.5376, -3.403, -5.1335, -4.8861, -5.1897, -5.0947, -5.4597, -5.3282, -5.4733, -3.4836, -5.2099, -5.686, -5.686, -5.8159, -5.8159, -5.816, -5.8161, -5.8164, -5.8167, -4.5721, -5.597, -5.9654, -5.9655, -5.9656, -5.9656, -5.1451, -4.841, -6.1413, -6.1413, -6.1414, -6.1414, -6.1419, -5.8548, -6.0016, -6.1698, -6.3549, -6.3549, -6.3549, -6.3549, -5.6856, -5.686, -4.876, -4.3877, -2.2587, -3.7006, -5.2045, -5.63, -5.4055, -5.6856, -4.4778, -5.008, -4.1693, -4.7538, -5.1877, -5.4848, -5.4138, -4.8803, -4.8476, -5.3348, -5.1329, -5.3117, -5.3994, -5.1032, -5.5206, -5.4354, -5.4991, -4.2631, -4.5487, -4.5487, -4.5487, -4.8903, -4.3954, -4.4346, -4.7837, -5.6313, -5.9105, -5.9111, -4.5079, -6.0864, -6.0867, -6.0876, -6.0879, -6.0889, -5.3274, -4.3385, -6.3, -6.3011, -6.1436, -6.5719, -6.5719, -6.5719, -6.5723, -6.5724, -6.5725, -6.5726, -6.573, -4.4315, -4.5646, -5.9127, -4.4688, -5.9102, -4.4123, -6.0858, -5.8815, -4.0141, -5.2462, -4.9299, -4.6562, -2.769, -5.5155, -4.1109, -4.8076, -5.2023, -4.7081, -5.5341, -4.6096, -5.0637, -5.1612, -5.1812, -5.3058, -5.413, -3.9193, -3.9458, -4.0596, -4.188, -4.2591, -5.3438, -5.46, -5.588, -5.7375, -5.7376, -5.7376, -5.7379, -5.7379, -5.7389, -5.9137, -5.9174, -6.127, -6.127, -6.1273, -6.1274, -6.1276, -6.1276, -6.128, -6.1284, -6.1284, -6.1318, -5.4615, -5.0641, -6.3989, -6.3989, -2.7745, -4.5566, -3.579, -5.3678, -5.4663, -3.2549, -4.9821, -5.2837, -5.7341, -5.5941, -4.9879, -5.4227, -4.9728, -5.4455, -5.2306, -5.4468, -5.4686, -5.4856, -5.628, -5.6289, -5.6632, -4.1613, -4.4826, -4.5614, -4.6467, -4.6468, -4.7402, -4.7402, -4.7402, -5.2389, -5.414, -5.4148, -4.6446, -5.6277, -5.6281, -5.8994, -5.8994, -5.9001, -5.9001, -5.9017, -5.9017, -5.902, -6.2741, -6.2741, -6.2741, -6.2741, -6.2741, -6.2741, -6.2741, -6.2741, -6.2741, -4.7439, -4.6828, -5.6254, -5.6287, -4.7872, -4.8836, -4.6648, -4.7645, -4.8015, -4.2546, -4.1365, -4.3666, -4.7382, -4.778, -4.7551, -3.7987, -5.1213, -4.6335, -5.17, -5.3244, -5.2606, -5.2538], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.2738, 1.2546, 1.2455, 1.2451, 1.24, 1.2185, 1.2183, 1.2163, 1.1976, 1.1974, 1.1967, 1.1866, 1.1769, 1.1679, 1.1679, 1.1679, 1.1679, 1.1679, 1.1679, 1.1678, 1.1669, 1.1666, 1.1666, 1.1664, 1.1442, 1.1439, 1.1427, 1.14, 1.1338, 1.1212, 1.0972, 1.0591, 1.0218, 0.8238, 0.9086, 0.9896, 0.8573, 0.9352, 1.0499, 0.7691, 0.8184, 0.9726, 0.7441, 0.7741, 0.9576, 0.6145, 0.4967, 0.6794, 0.9046, 0.984, 0.3014, -0.5224, 0.5859, 0.1152, 0.4853, -0.0487, 0.5631, -0.0751, 0.2949, 1.4461, 1.3992, 1.3657, 1.3657, 1.3537, 1.3537, 1.3536, 1.3536, 1.3532, 1.3529, 1.3496, 1.3494, 1.3381, 1.3379, 1.3379, 1.3379, 1.3314, 1.3171, 1.3167, 1.3167, 1.3166, 1.3166, 1.3161, 1.3154, 1.3023, 1.2886, 1.286, 1.286, 1.286, 1.286, 1.2619, 1.2615, 1.1344, 1.0576, 0.6219, 0.8009, 1.1028, 1.1422, 1.0137, 1.0869, 0.3611, 0.6077, -0.0352, 0.2922, 0.6642, 0.9259, 0.833, 0.1209, -0.0311, 0.5839, 0.1201, 0.3819, 0.2757, -0.6396, 0.5047, -0.2014, 0.1084, 1.5021, 1.4943, 1.4943, 1.4943, 1.4812, 1.4674, 1.4594, 1.4369, 1.4334, 1.4056, 1.405, 1.3865, 1.3839, 1.3837, 1.3828, 1.3824, 1.3814, 1.3662, 1.3661, 1.3526, 1.3516, 1.326, 1.3041, 1.3041, 1.3041, 1.3036, 1.3035, 1.3034, 1.3033, 1.303, 1.267, 1.2601, 1.2697, 1.1797, 1.2674, 1.1091, 1.2282, 1.1883, 0.8248, 1.0601, 0.9577, 0.8677, 0.1116, 1.1031, 0.3906, 0.732, 0.723, 0.3379, 0.9398, -0.146, -0.0624, 0.0918, 0.0528, 0.1395, -1.2789, 1.6784, 1.6779, 1.6753, 1.6721, 1.67, 1.6151, 1.6042, 1.594, 1.5781, 1.5781, 1.578, 1.5777, 1.5777, 1.5767, 1.5562, 1.5524, 1.5253, 1.5252, 1.525, 1.5248, 1.5247, 1.5247, 1.5242, 1.5239, 1.5239, 1.5206, 1.4933, 1.4893, 1.4766, 1.4766, 1.3596, 1.409, 1.2374, 1.3327, 1.1673, -0.3744, 0.7114, 0.9285, 1.2442, 1.0932, 0.5518, 0.8962, 0.0285, 0.544, -0.1461, 0.4052, -0.0349, -0.0966, 0.2973, 0.2586, -0.1417, 2.2204, 2.2031, 2.198, 2.1924, 2.1923, 2.1854, 2.1854, 2.1854, 2.1351, 2.1126, 2.1117, 2.1064, 2.079, 2.0785, 2.0271, 2.0271, 2.0263, 2.0263, 2.0246, 2.0246, 2.0242, 1.9345, 1.9345, 1.9345, 1.9345, 1.9345, 1.9345, 1.9345, 1.9345, 1.9345, 1.9268, 1.9095, 1.8872, 1.8862, 1.8091, 1.779, 1.7385, 1.7014, 1.5972, 1.4648, 0.7024, 0.7942, 1.03, 0.897, 0.4979, -0.9182, 0.8891, -0.1699, 0.2927, 0.8099, 0.2633, -0.7524]}, \"token.table\": {\"Topic\": [5, 2, 4, 1, 3, 5, 2, 3, 4, 1, 4, 5, 5, 5, 3, 4, 1, 2, 3, 4, 5, 1, 5, 1, 2, 5, 1, 2, 3, 4, 5, 4, 4, 4, 2, 3, 5, 1, 4, 5, 1, 1, 2, 3, 5, 2, 3, 4, 5, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 4, 1, 2, 3, 4, 5, 1, 2, 3, 5, 2, 2, 4, 5, 2, 4, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 5, 2, 1, 2, 3, 1, 2, 4, 1, 5, 5, 1, 2, 2, 5, 1, 3, 4, 5, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 4, 3, 2, 3, 2, 4, 3, 4, 2, 2, 1, 5, 3, 4, 5, 3, 4, 1, 5, 2, 1, 2, 4, 4, 2, 3, 3, 4, 1, 5, 1, 3, 4, 5, 1, 3, 4, 5, 1, 3, 5, 1, 2, 4, 5, 3, 4, 1, 2, 3, 4, 2, 4, 3, 4, 1, 2, 3, 1, 4, 2, 2, 4, 2, 3, 4, 3, 1, 3, 4, 5, 1, 3, 4, 5, 3, 3, 1, 2, 3, 5, 1, 3, 5, 5, 2, 5, 1, 2, 3, 4, 5, 4, 1, 4, 5, 5, 2, 3, 1, 1, 5, 5, 3, 3, 4, 5, 1, 5, 3, 5, 3, 1, 2, 3, 4, 1, 3, 5, 3, 4, 5, 5, 3, 3, 3, 2, 2, 3, 1, 2, 4, 4, 1, 2, 3, 5, 4, 2, 5, 2, 3, 1, 3, 4, 2, 3, 1, 2, 3, 4, 5, 1, 3, 5, 1, 5, 5, 2, 2, 2, 3, 4, 4, 3, 1, 2, 3, 4, 1, 3, 4, 5, 2, 3, 4, 5, 1, 3, 3, 5, 3, 5, 5, 1, 1, 4, 5, 3, 1, 4, 4, 4, 5, 1, 3, 5, 1, 2, 3, 4, 5, 5, 1, 3, 1, 3, 5, 4, 3, 1, 2, 3, 4, 1, 1, 2, 3, 1, 4, 1, 2, 3, 5, 1, 4, 5, 5, 1, 3, 1, 4, 2, 1, 3, 4, 1, 5, 2, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 2, 3, 1, 3, 1, 4, 3, 4, 1, 2, 2, 1, 2, 3, 4, 5, 1, 1, 3, 4, 5, 2, 2, 4, 4, 1, 2, 3, 1, 3, 2, 4, 2, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 2, 2, 2, 4, 5, 1, 1, 2, 3, 5, 1, 4, 5, 1, 3, 4, 5, 2, 3, 4, 1, 5], \"Freq\": [0.828819212330969, 0.8288479174260983, 0.8811970994531714, 0.19980110005255558, 0.7659042168681297, 0.927075384635385, 0.33429228479113876, 0.6685845695822775, 0.9670477773808428, 0.910915339218254, 0.9398557820934903, 0.9376774576294757, 0.744258435179519, 0.9272251659370855, 0.1565947290106525, 0.7829736450532625, 0.48135691523176105, 0.18835705378634127, 0.23021417684997267, 0.06278568459544709, 0.020928561531815697, 0.6559967070849894, 0.29155409203777305, 0.42288945828945873, 0.2927696249696253, 0.2602396666396669, 0.3524576053302243, 0.3383593011170153, 0.09868812949246279, 0.01409830421320897, 0.21147456319813457, 0.9395554153041349, 0.8390067387047854, 0.9398557918039512, 0.7739022723655192, 0.20479065699574867, 0.614371970987246, 0.6753815520213519, 0.20261446560640556, 0.06753815520213519, 0.8114282824134211, 0.15447180858946907, 0.20596241145262545, 0.4119248229052509, 0.2574530143157818, 0.08733114015753393, 0.08733114015753393, 0.17466228031506786, 0.6113179811027375, 0.7738971129564838, 0.8815205556251002, 0.19881817201540708, 0.3313636200256785, 0.06627272400513569, 0.3644999820282463, 0.5168980085491912, 0.2736518868789836, 0.06081153041755191, 0.06081153041755191, 0.09121729562632787, 0.02756920062197486, 0.22055360497579887, 0.08270760186592457, 0.6340916143054217, 0.02756920062197486, 0.11697086223222852, 0.8187960356255997, 0.29849815843850314, 0.26533169638978055, 0.1989987722923354, 0.18241554126797413, 0.04974969307308385, 0.6005402622250969, 0.12591973240203647, 0.18403653197220712, 0.08717519935525601, 0.870030405852697, 0.6821754477711971, 0.0974536353958853, 0.0974536353958853, 0.8288474357975189, 0.8390060423299539, 0.947591035468702, 0.8557337250843581, 0.0717366380424262, 0.0717366380424262, 0.2869465521697048, 0.5738931043394097, 0.22372117941705158, 0.027965147427131447, 0.503372653688366, 0.08389544228139434, 0.13982573713565724, 0.8196259779129296, 0.9621328497007192, 0.9291907461552437, 0.30576150041954575, 0.06115230008390915, 0.6115230008390915, 0.17902301967289028, 0.2685345295093354, 0.5370690590186707, 0.8322752607430738, 0.10403440759288422, 0.9088078952713687, 0.947583263475911, 0.9020463959104489, 0.7741721480407432, 0.9231487471590194, 0.6642415998161865, 0.15096399995822418, 0.18115679994986902, 0.03019279999164484, 0.09069948938097352, 0.09069948938097352, 0.7255959150477882, 0.09069948938097352, 0.15713486476487962, 0.4336126647942248, 0.24266396837107992, 0.1253100820276888, 0.04177002734256294, 0.8287712229260236, 0.8389984619501326, 0.8815329392981055, 0.040490262713002885, 0.9312760423990663, 0.8700417504832434, 0.9645874414104378, 0.8815215502482339, 0.9398242245961963, 0.9106451381947113, 0.9291907968424634, 0.9110083331308486, 0.8196259779129296, 0.6561360278174434, 0.13122720556348869, 0.13122720556348869, 0.8815247384022633, 0.9398040138719964, 0.8114875419748803, 0.8937377446406639, 0.9291915006871823, 0.9072169942472069, 0.8128356213033294, 0.1161193744719042, 0.9398240755801958, 0.9020527583373823, 0.7834389040425566, 0.850717354370492, 0.121531050624356, 0.945362449247479, 0.9270744957631845, 0.7419310140554405, 0.0824367793394934, 0.0824367793394934, 0.1648735586789868, 0.6109696792989, 0.171071510203692, 0.171071510203692, 0.024438787171955998, 0.8070417263939119, 0.06725347719949266, 0.06725347719949266, 0.36940558147298874, 0.36940558147298874, 0.18470279073649437, 0.04617569768412359, 0.9402024133302077, 0.9398063128687312, 0.03882629209292893, 0.4659155051151471, 0.19413146046464463, 0.2717840446505025, 0.8699839426588885, 0.07249866188824071, 0.7343617289330961, 0.14687234578661923, 0.2715323941686674, 0.6109478868795016, 0.1357661970843337, 0.7968423512743027, 0.11383462161061467, 0.8292293083315947, 0.8288456882080051, 0.7830813700208707, 0.6721709169080267, 0.2585272757338564, 0.07755818272015692, 0.9868949594783519, 0.08483564962178908, 0.08483564962178908, 0.5938495473525236, 0.25450694886536723, 0.5877356446838963, 0.20442978945526824, 0.1788760657733597, 0.02555372368190853, 0.8815116934210125, 0.9612402162605428, 0.3570668917385368, 0.24994682421697575, 0.10712006752156104, 0.28565351339082945, 0.19008475903335864, 0.6969774497889817, 0.09504237951667932, 0.8196259779129296, 0.9158816892778634, 0.08326197175253304, 0.5446403483252499, 0.07780576404646426, 0.05835432303484819, 0.05835432303484819, 0.23341729213939277, 0.9134438996355465, 0.3096722243053744, 0.4335411140275241, 0.18580333458322462, 0.8893983423734354, 0.773895942364624, 0.8815139410514355, 0.9109153144927746, 0.09540727141449486, 0.8586654427304538, 0.8196259876187032, 0.8815329176918005, 0.7834685007569232, 0.5987471547634224, 0.23949886190536898, 0.77177357065423, 0.22050673447263716, 0.8981448754864196, 0.05613405471790123, 0.9790893220366254, 0.46060039815986065, 0.18424015926394427, 0.2763602388959164, 0.09212007963197213, 0.4760642034753191, 0.06800917192504558, 0.44205961751279627, 0.17607175224377247, 0.08803587612188624, 0.7042870089750899, 0.9088078952713687, 0.7834351094865344, 0.839358579498262, 0.9139230796526234, 0.870492029866272, 0.22670096117146019, 0.7556698705715339, 0.2880971931115896, 0.5185749476008612, 0.11523887724463583, 0.9936031558121683, 0.43703950283874204, 0.04229414543600729, 0.4934316967534184, 0.014098048478669098, 0.8809160031538628, 0.727880577727909, 0.27295521664796585, 0.6733499113681182, 0.24485451322477025, 0.22728662732063454, 0.4545732546412691, 0.3125191125658725, 0.16752176852498618, 0.6700870740999447, 0.576754659872787, 0.07209433248409837, 0.14418866496819674, 0.16221224808922133, 0.07209433248409837, 0.774014655343558, 0.1346112444075753, 0.06730562220378765, 0.2442076332536266, 0.7326228997608798, 0.9376861670584719, 0.8700310532062189, 0.9279637420646245, 0.9880546016010517, 0.21748537470449078, 0.7394502739952686, 0.9888521730367849, 0.8393720929461699, 0.3564215464247903, 0.044552693303098787, 0.26731615981859275, 0.31186885312169155, 0.13949029317514747, 0.6695534072407079, 0.16738835181017697, 0.027898058635029494, 0.22295755069040812, 0.06270681113167728, 0.7106771928256759, 0.7442393944999885, 0.9586407413428957, 0.9401930574772429, 0.9419230342104358, 0.039246793092101495, 0.9868949594783519, 0.9271886716871968, 0.9270072497602682, 0.9109552552161923, 0.3896529986969399, 0.4453177127965028, 0.16699414229868856, 0.7834519036865796, 0.8824059090010091, 0.83897975973901, 0.8811970917745597, 0.32690947810163135, 0.6538189562032627, 0.8745253460377742, 0.08745253460377743, 0.8196259779129296, 0.06036278283314499, 0.5231441178872566, 0.32193484177677323, 0.05030231902762082, 0.05030231902762082, 0.8196259779129296, 0.09007806377225513, 0.8107025739502962, 0.433883503754569, 0.5785113383394254, 0.8196259779129296, 0.783112168737505, 0.783462024969455, 0.6360468040695494, 0.06360468040695494, 0.12720936081390988, 0.12720936081390988, 0.9109232259164581, 0.8824169819341559, 0.8128693170962569, 0.11612418815660813, 0.9476431162384763, 0.9398063128687312, 0.7498409046412706, 0.044108288508310035, 0.17643315403324014, 0.08821657701662007, 0.8120123071631704, 0.9785712174788246, 0.9272251630056402, 0.8196259779129296, 0.7968871413134937, 0.11384102018764196, 0.7264523259661354, 0.20755780741889585, 0.8700351825829825, 0.20115722189425117, 0.5632402213039033, 0.2413886662731014, 0.8097421851733427, 0.17047203898386162, 0.20432121383163857, 0.6129636414949157, 0.23464301425751477, 0.2559741973718343, 0.23464301425751477, 0.0853247324572781, 0.1706494649145562, 0.12451135310857588, 0.41503784369525293, 0.29052649058667707, 0.16601513747810118, 0.13402165776066505, 0.8376353610041565, 0.8114254356020458, 0.7828940082221191, 0.9109554437989827, 0.9398139646957576, 0.8815329176918005, 0.93982410745979, 0.910917012418167, 0.7738959348964445, 0.9291907494075728, 0.24278817788826765, 0.31215622871348697, 0.31215622871348697, 0.08671006353152416, 0.05202603811891449, 0.910915339218254, 0.20124345813396696, 0.20124345813396696, 0.06708115271132233, 0.5366492216905786, 0.7738942567694599, 0.6161969237681161, 0.3423316243156201, 0.839007308175677, 0.6846509685725144, 0.11410849476208573, 0.11410849476208573, 0.14615346516990183, 0.7307673258495091, 0.8436915821356716, 0.10546144776695895, 0.8700204316953993, 0.9398705848915276, 0.9088078952713687, 0.2145801792629352, 0.4291603585258704, 0.24523449058621166, 0.061308622646552915, 0.09196293396982938, 0.6470315917997164, 0.09954332181534098, 0.19908664363068196, 0.8288472525708451, 0.8700304526198552, 0.6823367620912685, 0.19495336059750526, 0.09747668029875263, 0.913284834011053, 0.5787854207523634, 0.1578505692960991, 0.1315421410800826, 0.1315421410800826, 0.20217103192234795, 0.13478068794823198, 0.6065130957670439, 0.9109153600093723, 0.9868949594783519, 0.8390037257426892, 0.81962599475556, 0.29245902956208125, 0.45957847502612764, 0.2506791681960696, 0.9109153144927746, 0.9271889119109177], \"Term\": [\"7b\", \"abierto\", \"acce\", \"access\", \"access\", \"advancements\", \"alphabet\", \"alphabet\", \"altman\", \"always\", \"ama\", \"amazon\", \"amzn\", \"anselmo\", \"api\", \"api\", \"app\", \"app\", \"app\", \"app\", \"app\", \"appeared\", \"appeared\", \"apple\", \"apple\", \"apple\", \"artificial\", \"artificial\", \"artificial\", \"artificial\", \"artificial\", \"artificiale\", \"arxivlabs\", \"ask\", \"atenci\\u00f3n\", \"authorities\", \"authorities\", \"available\", \"available\", \"available\", \"baidu\", \"big\", \"big\", \"big\", \"big\", \"business\", \"business\", \"business\", \"business\", \"ca\", \"capabilities\", \"ceo\", \"ceo\", \"ceo\", \"ceo\", \"chatbot\", \"chatbot\", \"chatbot\", \"chatbot\", \"chatbot\", \"chatgpt\", \"chatgpt\", \"chatgpt\", \"chatgpt\", \"chatgpt\", \"che\", \"che\", \"china\", \"china\", \"china\", \"china\", \"china\", \"chinese\", \"chinese\", \"chinese\", \"chinese\", \"chino\", \"chips\", \"chips\", \"chips\", \"ch\\u00ednh\", \"cinese\", \"cisco\", \"column\", \"com\", \"com\", \"com\", \"com\", \"company\", \"company\", \"company\", \"company\", \"company\", \"construed\", \"content\", \"contents\", \"cost\", \"cost\", \"cost\", \"could\", \"could\", \"could\", \"country\", \"country\", \"coverage\", \"credit\", \"c\\u00f3digo\", \"c\\u00f3mo\", \"daily\", \"data\", \"data\", \"data\", \"data\", \"deep\", \"deep\", \"deep\", \"deep\", \"deepseek\", \"deepseek\", \"deepseek\", \"deepseek\", \"deepseek\", \"deepseekdeepseek\", \"della\", \"demostrado\", \"device\", \"device\", \"devices\", \"di\", \"directamente\", \"directly\", \"donald\", \"d\\u00f3lares\", \"early\", \"educational\", \"emergence\", \"emergence\", \"emergence\", \"europe\", \"event\", \"everything\", \"exclusive\", \"explicarte\", \"february\", \"figure\", \"figure\", \"flag\", \"flyer\", \"fraction\", \"framework\", \"framework\", \"free\", \"funciones\", \"get\", \"get\", \"get\", \"get\", \"getty\", \"getty\", \"getty\", \"getty\", \"giant\", \"giant\", \"giant\", \"global\", \"global\", \"global\", \"global\", \"going\", \"gold\", \"google\", \"google\", \"google\", \"google\", \"gpu\", \"gpu\", \"headlines\", \"headlines\", \"high\", \"high\", \"high\", \"home\", \"home\", \"house\", \"huang\", \"h\\u00e0nh\", \"ia\", \"ia\", \"ia\", \"iab\", \"illustration\", \"illustration\", \"illustration\", \"illustration\", \"images\", \"images\", \"images\", \"images\", \"impressive\", \"including\", \"industry\", \"industry\", \"industry\", \"industry\", \"information\", \"information\", \"information\", \"informational\", \"inteligencia\", \"inteligencia\", \"intelligence\", \"intelligence\", \"intelligence\", \"intelligence\", \"intelligence\", \"intelligenza\", \"january\", \"january\", \"january\", \"janus\", \"jensen\", \"jin\", \"jinping\", \"join\", \"join\", \"joining\", \"justin\", \"know\", \"kong\", \"kong\", \"korea\", \"korea\", \"language\", \"language\", \"large\", \"last\", \"last\", \"last\", \"last\", \"latest\", \"latest\", \"latest\", \"leading\", \"leading\", \"leading\", \"learn\", \"learning\", \"llama\", \"llms\", \"mercado\", \"meta\", \"meta\", \"microsoft\", \"microsoft\", \"microsoft\", \"mini\", \"model\", \"model\", \"model\", \"model\", \"modello\", \"modelo\", \"modelo\", \"modelos\", \"modelos\", \"models\", \"models\", \"models\", \"momento\", \"momento\", \"new\", \"new\", \"new\", \"new\", \"new\", \"news\", \"news\", \"news\", \"newsletter\", \"newsletter\", \"newsletters\", \"nhng\", \"nvda\", \"nvidia\", \"o1\", \"o1\", \"o3\", \"ollama\", \"one\", \"one\", \"one\", \"one\", \"open\", \"open\", \"open\", \"open\", \"openai\", \"openai\", \"openai\", \"originally\", \"page\", \"parec\\u00eda\", \"part\", \"part\", \"partners\", \"passada\", \"paused\", \"performance\", \"photo\", \"photo\", \"photo\", \"pichai\", \"platform\", \"plus\", \"plusteam\", \"pro\", \"pro\", \"protection\", \"protection\", \"purposes\", \"r1\", \"r1\", \"r1\", \"r1\", \"r1\", \"rating\", \"reasoning\", \"reasoning\", \"recently\", \"recently\", \"recommendation\", \"reddit\", \"reinforcement\", \"release\", \"release\", \"release\", \"release\", \"reporting\", \"researchers\", \"rise\", \"rise\", \"rivals\", \"rush\", \"said\", \"said\", \"said\", \"said\", \"sales\", \"sam\", \"screen\", \"securities\", \"services\", \"services\", \"shows\", \"shows\", \"si\", \"source\", \"source\", \"source\", \"south\", \"south\", \"spending\", \"spending\", \"startup\", \"startup\", \"startup\", \"startup\", \"startup\", \"stocks\", \"stocks\", \"stocks\", \"stocks\", \"store\", \"store\", \"stories\", \"storm\", \"success\", \"sulla\", \"sullivan\", \"suo\", \"suspended\", \"table\", \"tariffs\", \"tech\", \"tech\", \"tech\", \"tech\", \"tech\", \"techmeme\", \"technology\", \"technology\", \"technology\", \"technology\", \"terremoto\", \"th\", \"th\", \"tools\", \"top\", \"top\", \"top\", \"trained\", \"trained\", \"trump\", \"trump\", \"tsmc\", \"unsplash\", \"updates\", \"us\", \"us\", \"us\", \"us\", \"us\", \"via\", \"via\", \"via\", \"vn\", \"v\\u00e0\", \"wall\", \"wall\", \"wall\", \"watchdog\", \"week\", \"week\", \"week\", \"week\", \"weekly\", \"weekly\", \"weekly\", \"wiz\", \"words\", \"work\", \"works\", \"world\", \"world\", \"world\", \"xi\", \"yoyo\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 3, 4, 5, 2]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el493227892989310722249166097\", ldavis_el493227892989310722249166097_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el493227892989310722249166097\", ldavis_el493227892989310722249166097_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el493227892989310722249166097\", ldavis_el493227892989310722249166097_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize LDA results\n",
    "pyLDAvis.enable_notebook()\n",
    "lda_vis = pyLDAvis.lda_model.prepare(lda_model, count_matrix, count_vectorizer)\n",
    "pyLDAvis.display(lda_vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5414e5b-3a1a-4756-bd0d-80be8cd47617",
   "metadata": {},
   "source": [
    "The LDA visualization show five distinct topics, with Topic 1 being the most prevalent and Topics 2 and 5 showing some overlap. The most salient terms include AI-related words like \"openai,\" \"nvidia,\" and \"deepseek,\" alongside technical and business-related terms, indicating a focus on AI companies, technologies, and partnerships. Term frequency analysis highlights \"deepseek\" as the most frequent term. The marginal topic distribution shows the relative importance of different topics within the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460aba72-5854-4391-a614-fd1544457ada",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "The higher coherence score will be selected as the best model as it indicates more interpretable topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34cac8ea-5112-48c1-92a0-e21c432dd43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Scores:\n",
      "NMF: 0.4934\n",
      "LSA: 0.4854\n",
      "LDA: 0.2878\n"
     ]
    }
   ],
   "source": [
    "# Calculate coherence scores for each model\n",
    "def calculate_coherence(model, feature_names, doc_term_matrix):\n",
    "    coherence_scores = []\n",
    "    for topic in model.components_:\n",
    "        top_words = [feature_names[i] for i in topic.argsort()[:-10 - 1:-1]]\n",
    "        word_indices = [list(feature_names).index(word) for word in top_words]\n",
    "        topic_vectors = doc_term_matrix[:, word_indices]\n",
    "        pairwise_similarities = cosine_similarity(topic_vectors.T)\n",
    "        coherence = pairwise_similarities.mean()\n",
    "        coherence_scores.append(coherence)\n",
    "    return coherence_scores\n",
    "\n",
    "nmf_coherence = calculate_coherence(nmf_model, tfidf_vectorizer.get_feature_names_out(), tfidf_matrix)\n",
    "lsa_coherence = calculate_coherence(lsa_model, tfidf_vectorizer.get_feature_names_out(), tfidf_matrix)\n",
    "lda_coherence = calculate_coherence(lda_model, count_vectorizer.get_feature_names_out(), count_matrix)\n",
    "\n",
    "print(\"\\nCoherence Scores:\")\n",
    "print(f\"NMF: {np.mean(nmf_coherence):.4f}\")\n",
    "print(f\"LSA: {np.mean(lsa_coherence):.4f}\")\n",
    "print(f\"LDA: {np.mean(lda_coherence):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27b29aa-e43b-4f09-aa0a-9759dbd0b521",
   "metadata": {},
   "source": [
    "Use the most frequent words to try to discern what semantic groups the unsupervised topics might have identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "947946ed-d656-4a28-910f-a57fb1d5672c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Identified semantic groups:\n",
      "\n",
      "Group_1-3: Topic 2, Topic 4\n",
      "Words: r1, chatgpt, o1, ia\n",
      "\n",
      "Group_2-3: Topic 3, Topic 4\n",
      "Words: artificial\n"
     ]
    }
   ],
   "source": [
    "# Extract top words and their frequencies for each topic\n",
    "n_top_words = 15\n",
    "topic_word_freq = []\n",
    "\n",
    "for topic_idx, topic in enumerate(nmf_model.components_):\n",
    "    top_features_ind = topic.argsort()[:-n_top_words - 1:-1]\n",
    "    top_features = tfidf_vectorizer.get_feature_names_out()[top_features_ind]\n",
    "    weights = topic[top_features_ind]\n",
    "    topic_word_freq.append(dict(zip(top_features, weights)))\n",
    "\n",
    "# Calculate the relevance of each word across all topics\n",
    "word_topic_relevance = {}\n",
    "for topic_idx, word_freq in enumerate(topic_word_freq):\n",
    "    for word, freq in word_freq.items():\n",
    "        if word not in word_topic_relevance:\n",
    "            word_topic_relevance[word] = []\n",
    "        word_topic_relevance[word].append((topic_idx, freq))\n",
    "        \n",
    "# Identify semantic groups based on word relevance across topics\n",
    "threshold = 0.05\n",
    "semantic_groups = {}\n",
    "for word, relevances in word_topic_relevance.items():\n",
    "    relevant_topics = [topic for topic, score in relevances if score >= threshold]\n",
    "    if len(relevant_topics) > 1:\n",
    "        group_name = f\"Group_{'-'.join(map(str, relevant_topics))}\"\n",
    "        if group_name not in semantic_groups:\n",
    "            semantic_groups[group_name] = []\n",
    "        semantic_groups[group_name].append(word)\n",
    "\n",
    "# Display the identified semantic groups with interpretations\n",
    "topic_interpretations = [\n",
    "    \"Topic 1\",\n",
    "    \"Topic 2\",\n",
    "    \"Topic 3\",\n",
    "    \"Topic 4\",\n",
    "    \"Topic 5\"\n",
    "]\n",
    "\n",
    "print(\"\\nIdentified semantic groups:\")\n",
    "for group, words in semantic_groups.items():\n",
    "    topics = [int(t) for t in group.split('_')[1].split('-')]\n",
    "    interpretations = [topic_interpretations[t] for t in topics]\n",
    "    print(f\"\\n{group}: {', '.join(interpretations)}\")\n",
    "    print(f\"Words: {', '.join(words)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971b085a-34d3-4702-9832-c05c7c3bd6a5",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14873290-1118-44a1-9fb3-20e7bc845cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text, fw):\n",
    "    words = set(text.split())\n",
    "    return {word: True for word in words if word in fw}\n",
    "\n",
    "# Create feature words set\n",
    "word_cutoff = 5\n",
    "tokens = [w for t in news_df['Tokens'] for w in t]\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "feature_words = {word for word, count in word_dist.items() if count > word_cutoff}\n",
    "\n",
    "# Create feature sets\n",
    "featuresets = [(conv_features(text, feature_words), label) for text, label in zip(news_df['Cleaned_Text'], news_df['source'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4d22711-2dc4-4517-8e21-a4ac7d8a1e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = int(len(featuresets) * 0.2)\n",
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e09c6ee-0fbd-473d-8a5a-ace191f3e04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14814814814814814\n",
      "Most Informative Features\n",
      "                   daily = True           Ventur : Busine =     24.1 : 1.0\n",
      "                 embrace = True           Arxiv. : Busine =     22.8 : 1.0\n",
      "                     che = True           Macity : Busine =     21.7 : 1.0\n",
      "                   large = True           Hackad : Busine =     21.7 : 1.0\n",
      "                    news = True           Fox Ne : Busine =     21.7 : 1.0\n",
      "                  nvidia = True           Market : Busine =     21.7 : 1.0\n",
      "                    show = True           Techme : Busine =     21.7 : 1.0\n",
      "                 version = True           Techme : Busine =     21.7 : 1.0\n",
      "                 welcome = True           Fox Ne : Busine =     21.7 : 1.0\n",
      "                  access = True           Macspa : Busine =     19.5 : 1.0\n",
      "                     big = True           Weeram : Busine =     19.5 : 1.0\n",
      "                   build = True           Digida : Busine =     19.5 : 1.0\n",
      "               challenge = True           Javaco : Busine =     19.5 : 1.0\n",
      "                  chinas = True           Next B : Busine =     19.5 : 1.0\n",
      "                 concern = True           CBC Ne : Busine =     19.5 : 1.0\n",
      "                    deep = True           Anfalm : Busine =     19.5 : 1.0\n",
      "               developer = True           Opera. : Busine =     19.5 : 1.0\n",
      "                  future = True           Singul : Busine =     19.5 : 1.0\n",
      "                    gain = True           The St : Busine =     19.5 : 1.0\n",
      "                  google = True           ANSA.i : Busine =     19.5 : 1.0\n",
      "                    hear = True           Yanko  : Busine =     19.5 : 1.0\n",
      "                  impact = True           The St : Busine =     19.5 : 1.0\n",
      "                 january = True           Simonw : Busine =     19.5 : 1.0\n",
      "                     key = True           Techre : Busine =     19.5 : 1.0\n",
      "                    lead = True           Qodo.a : Busine =     19.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))\n",
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72e6509d-2070-49f1-8588-e4e79488dd31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted source: Hackaday\n",
      "Predicted source: MacRumors\n",
      "Predicted source: Digiday\n",
      "Predicted source: Qodo.ai\n",
      "Predicted source: Spacewar.com\n",
      "Predicted source: Penny-arcade.com\n",
      "Predicted source: MacRumors\n",
      "Predicted source: Penny-arcade.com\n",
      "Predicted source: Digitimes\n",
      "Predicted source: Spacewar.com\n"
     ]
    }
   ],
   "source": [
    "def classify_article(article_text):\n",
    "    features = conv_features(article_text, feature_words)\n",
    "    return classifier.classify(features)\n",
    "\n",
    "new_articles = news_df['Cleaned_Text'].tolist()[:10]  # Take first 10 articles as an example\n",
    "for article in new_articles:\n",
    "    predicted_source = classify_article(article)\n",
    "    print(f\"Predicted source: {predicted_source}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f8fca0-015e-40e8-afed-fdea45bafe00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
