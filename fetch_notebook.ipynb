{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefaf43d-8a99-4624-962a-f7d602ead975",
   "metadata": {},
   "outputs": [],
   "source": [
    "from newsapi import NewsApiClient\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from typing import Dict, List, Any\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d9950a-471f-4465-a9a1-8faf7ac9550f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsCollector:\n",
    "    def __init__(self, api_key: str):\n",
    "        \"\"\"Initialize NewsAPI client with API key\"\"\"\n",
    "        self.newsapi = NewsApiClient(api_key=api_key)\n",
    "        self.article_limit = 100\n",
    "        \n",
    "    def process_article(self, article: Dict) -> Dict:\n",
    "        \"\"\"Process a single article and extract relevant fields\"\"\"\n",
    "        return {\n",
    "            'source_id': article['source'].get('id', ''),\n",
    "            'source_name': article['source'].get('name', ''),\n",
    "            'author': article.get('author', ''),\n",
    "            'title': article.get('title', ''),\n",
    "            'description': article.get('description', ''),\n",
    "            'url': article.get('url', ''),\n",
    "            'urlToImage': article.get('urlToImage', ''),\n",
    "            'publishedAt': pd.to_datetime(article.get('publishedAt')),\n",
    "            'content': article.get('content', '')\n",
    "        }\n",
    "        \n",
    "    def fetch_articles(self, query: str) -> pd.DataFrame:\n",
    "        \"\"\"Fetch articles with error handling and rate limiting\"\"\"\n",
    "        try:\n",
    "            end_date = dt.datetime.now()\n",
    "            start_date = end_date - dt.timedelta(days=7)\n",
    "            \n",
    "            logger.info(f\"Fetching articles for query: {query}\")\n",
    "            \n",
    "            response = self.newsapi.get_everything(\n",
    "                q=query,\n",
    "                from_param=start_date.strftime('%Y-%m-%d'),\n",
    "                to=end_date.strftime('%Y-%m-%d'),\n",
    "                language='en',\n",
    "                sort_by='relevancy',\n",
    "                page_size=self.article_limit\n",
    "            )\n",
    "            \n",
    "            if not response or 'articles' not in response:\n",
    "                logger.error(\"No articles found in response\")\n",
    "                return pd.DataFrame()\n",
    "            \n",
    "            processed_articles = []\n",
    "            for article in response['articles'][:self.article_limit]:\n",
    "                processed_articles.append(self.process_article(article))\n",
    "            \n",
    "            df = pd.DataFrame(processed_articles)\n",
    "            \n",
    "            columns_order = [\n",
    "                'source_id',\n",
    "                'source_name',\n",
    "                'author',\n",
    "                'title',\n",
    "                'description',\n",
    "                'url',\n",
    "                'urlToImage',\n",
    "                'publishedAt',\n",
    "                'content'\n",
    "            ]\n",
    "            \n",
    "            df = df[columns_order]\n",
    "            df.index.name = 'Unnamed: 0'\n",
    "            \n",
    "            logger.info(f\"Successfully collected {len(df)} articles\")\n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error fetching articles: {str(e)}\")\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "    def save_articles(self, df: pd.DataFrame, query: str) -> None:\n",
    "        \"\"\"Save articles to CSV with date in filename\"\"\"\n",
    "        if df.empty:\n",
    "            logger.warning(\"No articles to save\")\n",
    "            return\n",
    "        \n",
    "        date_str = dt.datetime.now().strftime('%Y%m%d')\n",
    "        filename = f\"{query}_{date_str}.csv\"\n",
    "        \n",
    "        df.to_csv(filename)\n",
    "        logger.info(f\"Saved {len(df)} articles to {filename}\")\n",
    "        \n",
    "        self.print_data_quality_report(df)\n",
    "        \n",
    "    def print_data_quality_report(self, df: pd.DataFrame) -> None:\n",
    "        \"\"\"Print data quality statistics\"\"\"\n",
    "        print(\"\\nData Quality Report:\")\n",
    "        print(f\"Total articles: {len(df)}\")\n",
    "        for column in df.columns:\n",
    "            print(f\"Missing {column}: {df[column].isna().sum()}\")\n",
    "        print(\"\\nDate range:\")\n",
    "        print(f\"Earliest article: {df['publishedAt'].min()}\")\n",
    "        print(f\"Latest article: {df['publishedAt'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0d04e2-8d33-45c4-a8cd-8726d0090b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize collector\n",
    "API_KEY = \"your_api_key_here\"\n",
    "collector = NewsCollector(API_KEY)\n",
    "\n",
    "# Define search query\n",
    "query = \"deepseek\"\n",
    "\n",
    "# Fetch and save articles\n",
    "df = collector.fetch_articles(query)\n",
    "collector.save_articles(df, query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
